{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations with IBM\n",
    "\n",
    "Several recommendation methods are investigated on real data from the IBM Watson Studio platform. \n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "I. [Exploratory Data Analysis](#Exploratory-Data-Analysis)<br>\n",
    "II. [Rank Based Recommendations](#Rank)<br>\n",
    "III. [User-User Based Collaborative Filtering](#User-User)<br>\n",
    "IV. [Content Based Recommendations](#Content-Recs)<br>\n",
    "V. [Matrix Factorization](#Matrix-Fact)<br>\n",
    "VI. [Extras & Concluding](#conclusions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries and packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import test modules\n",
    "import project_tests as t\n",
    "\n",
    "# Packages and libraries for content based recs\n",
    "\n",
    "import re\n",
    "\n",
    "# nlp packages\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# data processing packages\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# import linear kernel to compute the dot product\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 2 decimal places in output display\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "# Don't wrap dataframe across additional lines\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "\n",
    "# Set the maximum widths of columns\n",
    "pd.set_option(\"display.max_colwidth\", 90)\n",
    "\n",
    "# Set max rows displayed in output to 20\n",
    "pd.set_option(\"display.max_rows\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv('data/user-item-interactions.csv')\n",
    "df_content = pd.read_csv('data/articles_community.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier data analysis and experimentation</td>\n",
       "      <td>ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>b96a4f2e92d8572034b1e9b28f9ac673765cd074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>06485706b34a5c9bf2a0ecdac41daf7e7654ceb7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>f01220c46fc92c6e6b161b1849de11faacd7ccb2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                                                             title                                     email\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier data analysis and experimentation  ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7\n",
       "1      1314.0                                      healthcare python streaming application demo  083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b\n",
       "2      1429.0                                        use deep learning for image classification  b96a4f2e92d8572034b1e9b28f9ac673765cd074\n",
       "3      1338.0                                         ml optimization using cognitive assistant  06485706b34a5c9bf2a0ecdac41daf7e7654ceb7\n",
       "4      1276.0                                         deploy your python model as a restful api  f01220c46fc92c6e6b161b1849de11faacd7ccb2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show df to get an idea of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VID...</td>\n",
       "      <td>Detect bad readings in real time using Python and Streaming Analytics.</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streaming Analytics</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n * kaggle.com\\r\\n\\r\\nCommunicating data s...</td>\n",
       "      <td>See the forest, see the trees. Here lies the challenge in both performing and presenti...</td>\n",
       "      <td>Communicating data science: A guide to presenting your work</td>\n",
       "      <td>Live</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Paths\\r\\n * Courses * Our Courses\\r\\n    * ...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Big Data.</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCALE - BOOST THE PERFORMANCE OF YOUR\\r\\nDI...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of scaling persistent storage, but introdu...</td>\n",
       "      <td>DataLayer Conference: Boost the performance of your distributed database</td>\n",
       "      <td>Live</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VID...</td>\n",
       "      <td>This video demonstrates the power of IBM DataScience Experience using a simple New Yor...</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    doc_body                                                                            doc_description                                                             doc_full_name doc_status  article_id\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VID...                     Detect bad readings in real time using Python and Streaming Analytics.                Detect Malfunctioning IoT Sensors with Streaming Analytics       Live           0\n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n * kaggle.com\\r\\n\\r\\nCommunicating data s...  See the forest, see the trees. Here lies the challenge in both performing and presenti...               Communicating data science: A guide to presenting your work       Live           1\n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Paths\\r\\n * Courses * Our Courses\\r\\n    * ...                                      Here’s this week’s news in Data Science and Big Data.                                This Week in Data Science (April 18, 2017)       Live           2\n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCALE - BOOST THE PERFORMANCE OF YOUR\\r\\nDI...  Learn how distributed DBs solve the problem of scaling persistent storage, but introdu...  DataLayer Conference: Boost the performance of your distributed database       Live           3\n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VID...  This video demonstrates the power of IBM DataScience Experience using a simple New Yor...                             Analyze NY Restaurant data using Spark in DSX       Live           4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show df_content to get an idea of the data\n",
    "df_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Exploratory-Data-Analysis\">Part I : Exploratory Data Analysis</a>\n",
    "\n",
    "First we provide some insight into the descriptive statistics of the data.\n",
    "\n",
    "`1.` _What is the distribution of how many articles a user interacts with in the dataset?  Visual and descriptive statistics to assist with giving a look at the number of times each user interacts with an article._  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique user emails is 5148.\n"
     ]
    }
   ],
   "source": [
    "# The number of unique emails\n",
    "print(\"The number of unique user emails is {}.\".format(df.email.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique articles is 1051.\n"
     ]
    }
   ],
   "source": [
    "# The number of unique articles \n",
    "print(\"The number of unique articles is {}.\".format(df_content.article_id.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000b6387a0366322d7fbfc6434af145adf7fed1</td>\n",
       "      <td>[1314.0, 732.0, 173.0, 1354.0, 43.0, 1232.0, 1162.0, 124.0, 1337.0, 349.0, 43.0, 288.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001055fc0bb67f71e8fa17002342b256a30254cd</td>\n",
       "      <td>[124.0, 1386.0, 254.0, 390.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00148e4911c7e04eeff8def7bbbdaf1c59c2c621</td>\n",
       "      <td>[1386.0, 932.0, 258.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001a852ecbd6cc12ab77a785efa137b2646505fe</td>\n",
       "      <td>[349.0, 957.0, 1364.0, 593.0, 1364.0, 232.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001fc95b90da5c3cb12c501d201a915e4f093290</td>\n",
       "      <td>[1364.0, 379.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      email                                                                                 article_id\n",
       "0  0000b6387a0366322d7fbfc6434af145adf7fed1  [1314.0, 732.0, 173.0, 1354.0, 43.0, 1232.0, 1162.0, 124.0, 1337.0, 349.0, 43.0, 288.0...\n",
       "1  001055fc0bb67f71e8fa17002342b256a30254cd                                                              [124.0, 1386.0, 254.0, 390.0]\n",
       "2  00148e4911c7e04eeff8def7bbbdaf1c59c2c621                                                                     [1386.0, 932.0, 258.0]\n",
       "3  001a852ecbd6cc12ab77a785efa137b2646505fe                                               [349.0, 957.0, 1364.0, 593.0, 1364.0, 232.0]\n",
       "4  001fc95b90da5c3cb12c501d201a915e4f093290                                                                            [1364.0, 379.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table to keep track of the articles accessed by a user\n",
    "articles_per_user = pd.pivot_table(df,\n",
    "                    values=['article_id'],\n",
    "                    index='email',\n",
    "                    aggfunc={'article_id': list})\n",
    "articles_per_user.reset_index(inplace=True)\n",
    "\n",
    "# Check the outcome\n",
    "articles_per_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>article_id</th>\n",
       "      <th>articles_count</th>\n",
       "      <th>unique_articles_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>2b6c0f514c2f2b04ad3c4583407dccd0810469ee</td>\n",
       "      <td>[362.0, 409.0, 409.0, 302.0, 409.0, 14.0, 29.0, 1293.0, 1429.0, 1293.0, 720.0, 1304.0,...</td>\n",
       "      <td>364</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>77959baaa9895a7e2bdc9297f8b27c1b6f2cb52a</td>\n",
       "      <td>[943.0, 658.0, 109.0, 43.0, 1170.0, 1172.0, 1314.0, 43.0, 1338.0, 1160.0, 1276.0, 33.0...</td>\n",
       "      <td>363</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>2f5c7feae533ce046f2cb16fb3a29fe00528ed66</td>\n",
       "      <td>[173.0, 1165.0, 1427.0, 651.0, 1274.0, 1165.0, 1274.0, 1425.0, 202.0, 1293.0, 1429.0, ...</td>\n",
       "      <td>170</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>a37adec71b667b297ed2440a9ff7dad427c7ac85</td>\n",
       "      <td>[1293.0, 409.0, 20.0, 1165.0, 1430.0, 1175.0, 939.0, 1425.0, 1368.0, 1274.0, 1175.0, 1...</td>\n",
       "      <td>169</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>8510a5010a5d4c89f5b07baac6de80cd12cfaf93</td>\n",
       "      <td>[930.0, 1057.0, 1314.0, 793.0, 1368.0, 1396.0, 1368.0, 1396.0, 793.0, 427.0, 833.0, 13...</td>\n",
       "      <td>160</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1b520f0f65c0aee52d4235f92fb2de58fa966635</td>\n",
       "      <td>[1166.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>7a67e4a2902a20062e1f2a6835b6e099b34b4f6c</td>\n",
       "      <td>[50.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>c4b7e639e91b1d18e5b9c000f0ad3354888fcdde</td>\n",
       "      <td>[115.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>7a7fb282789944665ffc1cddee5ddbdbd7ca9f64</td>\n",
       "      <td>[299.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>9655144418d25a0e074616840447e6e5dbef0069</td>\n",
       "      <td>[57.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5148 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         email                                                                                 article_id  articles_count  unique_articles_count\n",
       "910   2b6c0f514c2f2b04ad3c4583407dccd0810469ee  [362.0, 409.0, 409.0, 302.0, 409.0, 14.0, 29.0, 1293.0, 1429.0, 1293.0, 720.0, 1304.0,...             364                    135\n",
       "2426  77959baaa9895a7e2bdc9297f8b27c1b6f2cb52a  [943.0, 658.0, 109.0, 43.0, 1170.0, 1172.0, 1314.0, 43.0, 1338.0, 1160.0, 1276.0, 33.0...             363                    135\n",
       "985   2f5c7feae533ce046f2cb16fb3a29fe00528ed66  [173.0, 1165.0, 1427.0, 651.0, 1274.0, 1165.0, 1274.0, 1425.0, 202.0, 1293.0, 1429.0, ...             170                     97\n",
       "3312  a37adec71b667b297ed2440a9ff7dad427c7ac85  [1293.0, 409.0, 20.0, 1165.0, 1430.0, 1175.0, 939.0, 1425.0, 1368.0, 1274.0, 1175.0, 1...             169                     97\n",
       "2680  8510a5010a5d4c89f5b07baac6de80cd12cfaf93  [930.0, 1057.0, 1314.0, 793.0, 1368.0, 1396.0, 1368.0, 1396.0, 793.0, 427.0, 833.0, 13...             160                     96\n",
       "...                                        ...                                                                                        ...             ...                    ...\n",
       "565   1b520f0f65c0aee52d4235f92fb2de58fa966635                                                                                   [1166.0]               1                      1\n",
       "2481  7a67e4a2902a20062e1f2a6835b6e099b34b4f6c                                                                                     [50.0]               1                      1\n",
       "4003  c4b7e639e91b1d18e5b9c000f0ad3354888fcdde                                                                                    [115.0]               1                      1\n",
       "2483  7a7fb282789944665ffc1cddee5ddbdbd7ca9f64                                                                                    [299.0]               1                      1\n",
       "3035  9655144418d25a0e074616840447e6e5dbef0069                                                                                     [57.0]               1                      1\n",
       "\n",
       "[5148 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column that records how many articles a user accessed\n",
    "articles_per_user['articles_count'] = [len(x) for x in articles_per_user.article_id]\n",
    "\n",
    "# Create a column that records how many unique articles the user accessed\n",
    "articles_per_user['unique_articles_count'] = [len(set(x)) for x in articles_per_user.article_id]\n",
    "\n",
    "# Check the outcome\n",
    "articles_per_user.sort_values(by='articles_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1416, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many users accessed one article only\n",
    "one_article_users = articles_per_user[articles_per_user['articles_count'] == 1]\n",
    "one_article_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The histogram of the data\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(articles_per_user.articles_count, bins=20)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Articles accessed')\n",
    "plt.title('How many articles are accessed by a user')\n",
    "plt.xlim(1, 370)\n",
    "plt.ylim(1, 1500)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The histogram of the data\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(articles_per_user.unique_articles_count, bins=20)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Unique articles accessed')\n",
    "plt.title('How many unique articles are accessed by a user')\n",
    "plt.xlim(1, 140)\n",
    "plt.ylim(1, 1500)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles_count</th>\n",
       "      <th>unique_articles_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5148.00</td>\n",
       "      <td>5148.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.93</td>\n",
       "      <td>6.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.80</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>364.00</td>\n",
       "      <td>135.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       articles_count  unique_articles_count\n",
       "count         5148.00                5148.00\n",
       "mean             8.93                   6.54\n",
       "std             16.80                   9.99\n",
       "min              1.00                   1.00\n",
       "25%              1.00                   1.00\n",
       "50%              3.00                   3.00\n",
       "75%              9.00                   7.00\n",
       "max            364.00                 135.00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 numbers descriptive statistics for the number of articles accessed by users\n",
    "articles_per_user.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Boxplot for the unique articles accessed by a user\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.boxplot(articles_per_user.unique_articles_count, vert=False)\n",
    "\n",
    "plt.title('Unique articles counts per user')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1170.0</td>\n",
       "      <td>apache spark lab, part 1: basic concepts</td>\n",
       "      <td>1588af175b283915f597fc4719cbb2c8621c4fc2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1170.0</td>\n",
       "      <td>apache spark lab, part 1: basic concepts</td>\n",
       "      <td>363cb98a087e4a3eb6890fd1af2d418116f85ff8</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>2b6c0f514c2f2b04ad3c4583407dccd0810469ee</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>77959baaa9895a7e2bdc9297f8b27c1b6f2cb52a</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>c8afd6f4620184042cc48ca0eba9a657ac89e90e</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                       title                                     email  counts\n",
       "0      1170.0    apache spark lab, part 1: basic concepts  1588af175b283915f597fc4719cbb2c8621c4fc2      42\n",
       "1      1170.0    apache spark lab, part 1: basic concepts  363cb98a087e4a3eb6890fd1af2d418116f85ff8      41\n",
       "2      1429.0  use deep learning for image classification  2b6c0f514c2f2b04ad3c4583407dccd0810469ee      35\n",
       "3      1429.0  use deep learning for image classification  77959baaa9895a7e2bdc9297f8b27c1b6f2cb52a      35\n",
       "4      1429.0  use deep learning for image classification  c8afd6f4620184042cc48ca0eba9a657ac89e90e      25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe to record the number of times each user interacts with an article\n",
    "article_user = df.value_counts(ascending=False).to_frame('counts').reset_index()\n",
    "article_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33669.00</td>\n",
       "      <td>33669.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>848.38</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>492.26</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>349.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>996.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1320.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1444.00</td>\n",
       "      <td>42.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id    counts\n",
       "count    33669.00  33669.00\n",
       "mean       848.38      1.37\n",
       "std        492.26      1.18\n",
       "min          0.00      1.00\n",
       "25%        349.00      1.00\n",
       "50%        996.00      1.00\n",
       "75%       1320.00      1.00\n",
       "max       1444.00     42.00"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 Values descriptive statistics for how many times users interact with one article\n",
    "article_user.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% of individuals interact with 3.0 articles or fewer.\n",
      "The maximum number of user-article interactions by any user is 364.\n"
     ]
    }
   ],
   "source": [
    "# Fill in the median and maximum number of user_article interactions below\n",
    "\n",
    "median_val = df.groupby('email').count()['article_id'].median()\n",
    "print('50% of individuals interact with {} articles or fewer.'.format(median_val))\n",
    "max_views_by_user = df.groupby('email').count()['article_id'].max()\n",
    "print('The maximum number of user-article interactions by any user is {}.'.format(max_views_by_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` _Explore and remove duplicate articles from the `df_content` dataframe._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and explore duplicate articles\n",
    "duplicate_articles = df_content[df_content['article_id'].duplicated()]\n",
    "duplicate_articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Follow Sign in / Sign up Home About Insight Data Science Data Engineering Health Data ...</td>\n",
       "      <td>During the seven-week Insight Data Engineering Fellows Program recent grads and experi...</td>\n",
       "      <td>Graph-based machine learning</td>\n",
       "      <td>Live</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * Home\\r\\n * Data Science Experience\\r\\n * ...</td>\n",
       "      <td>One of the earliest documented catalogs was compiled at the great library of Alexandri...</td>\n",
       "      <td>How smart catalogs can turn the big data flood into an ocean of opportunity</td>\n",
       "      <td>Live</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>Homepage Follow Sign in Get started Homepage * Home\\r\\n * Data Science Experience\\r\\n ...</td>\n",
       "      <td>Today’s world of data science leverages data from various sources. Commonly, these sou...</td>\n",
       "      <td>Using Apache Spark as a parallel processing framework for accessing REST based data se...</td>\n",
       "      <td>Live</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>This video shows you how to construct queries to access the primary index through the ...</td>\n",
       "      <td>This video shows you how to construct queries to access the primary index through the API</td>\n",
       "      <td>Use the Primary Index</td>\n",
       "      <td>Live</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Homepage Follow Sign in Get started * Home\\r\\n * Data Science Experience\\r\\n * Data Ca...</td>\n",
       "      <td>If you are like most data scientists, you are probably spending a lot of time to clean...</td>\n",
       "      <td>Self-service data preparation with IBM Data Refinery</td>\n",
       "      <td>Live</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      doc_body                                                                            doc_description                                                                              doc_full_name doc_status  article_id\n",
       "365  Follow Sign in / Sign up Home About Insight Data Science Data Engineering Health Data ...  During the seven-week Insight Data Engineering Fellows Program recent grads and experi...                                                               Graph-based machine learning       Live          50\n",
       "692  Homepage Follow Sign in / Sign up Homepage * Home\\r\\n * Data Science Experience\\r\\n * ...  One of the earliest documented catalogs was compiled at the great library of Alexandri...                How smart catalogs can turn the big data flood into an ocean of opportunity       Live         221\n",
       "761  Homepage Follow Sign in Get started Homepage * Home\\r\\n * Data Science Experience\\r\\n ...  Today’s world of data science leverages data from various sources. Commonly, these sou...  Using Apache Spark as a parallel processing framework for accessing REST based data se...       Live         398\n",
       "970  This video shows you how to construct queries to access the primary index through the ...  This video shows you how to construct queries to access the primary index through the API                                                                      Use the Primary Index       Live         577\n",
       "971  Homepage Follow Sign in Get started * Home\\r\\n * Data Science Experience\\r\\n * Data Ca...  If you are like most data scientists, you are probably spending a lot of time to clean...                                       Self-service data preparation with IBM Data Refinery       Live         232"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [doc_body, doc_description, doc_full_name, doc_status, article_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove any rows that have the same article_id - only keep the first\n",
    "df_content.drop_duplicates(subset=['article_id'], keep='first', inplace=True)\n",
    "\n",
    "# Check the outcome\n",
    "df_content[df_content['article_id'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` _In the cells below we find:_\n",
    "\n",
    "**a.** _The number of unique articles that have an interaction with a user.  \n",
    "**b.** The number of unique articles in the dataset (whether they have any interactions or not).<br>\n",
    "**c.** The number of unique users in the dataset. (excluding null values) <br>\n",
    "**d.** The number of user-article interactions in the dataset._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25131</th>\n",
       "      <td>1016.0</td>\n",
       "      <td>why you should master r (even if it might eventually become obsolete)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29758</th>\n",
       "      <td>1393.0</td>\n",
       "      <td>the nurse assignment problem</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29759</th>\n",
       "      <td>20.0</td>\n",
       "      <td>working interactively with rstudio and notebooks in dsx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29760</th>\n",
       "      <td>1174.0</td>\n",
       "      <td>breast cancer wisconsin (diagnostic) data set</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29761</th>\n",
       "      <td>62.0</td>\n",
       "      <td>data visualization: the importance of excluding unnecessary details</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35264</th>\n",
       "      <td>224.0</td>\n",
       "      <td>using apply, sapply, lapply in r</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35276</th>\n",
       "      <td>961.0</td>\n",
       "      <td>beyond parallelize and collect</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35277</th>\n",
       "      <td>268.0</td>\n",
       "      <td>sector correlations shiny app</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35278</th>\n",
       "      <td>268.0</td>\n",
       "      <td>sector correlations shiny app</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35279</th>\n",
       "      <td>268.0</td>\n",
       "      <td>sector correlations shiny app</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35280</th>\n",
       "      <td>268.0</td>\n",
       "      <td>sector correlations shiny app</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35281</th>\n",
       "      <td>415.0</td>\n",
       "      <td>using machine learning to predict value of homes on airbnb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35282</th>\n",
       "      <td>846.0</td>\n",
       "      <td>pearson correlation aggregation on sparksql</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35283</th>\n",
       "      <td>268.0</td>\n",
       "      <td>sector correlations shiny app</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35284</th>\n",
       "      <td>162.0</td>\n",
       "      <td>an introduction to stock market data analysis with r (part 1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42749</th>\n",
       "      <td>647.0</td>\n",
       "      <td>getting started with apache mahout</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42750</th>\n",
       "      <td>965.0</td>\n",
       "      <td>data visualization playbook: revisiting the basics</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id                                                                  title email\n",
       "25131      1016.0  why you should master r (even if it might eventually become obsolete)   NaN\n",
       "29758      1393.0                                           the nurse assignment problem   NaN\n",
       "29759        20.0                working interactively with rstudio and notebooks in dsx   NaN\n",
       "29760      1174.0                          breast cancer wisconsin (diagnostic) data set   NaN\n",
       "29761        62.0    data visualization: the importance of excluding unnecessary details   NaN\n",
       "35264       224.0                                       using apply, sapply, lapply in r   NaN\n",
       "35276       961.0                                         beyond parallelize and collect   NaN\n",
       "35277       268.0                                          sector correlations shiny app   NaN\n",
       "35278       268.0                                          sector correlations shiny app   NaN\n",
       "35279       268.0                                          sector correlations shiny app   NaN\n",
       "35280       268.0                                          sector correlations shiny app   NaN\n",
       "35281       415.0             using machine learning to predict value of homes on airbnb   NaN\n",
       "35282       846.0                            pearson correlation aggregation on sparksql   NaN\n",
       "35283       268.0                                          sector correlations shiny app   NaN\n",
       "35284       162.0          an introduction to stock market data analysis with r (part 1)   NaN\n",
       "42749       647.0                                     getting started with apache mahout   NaN\n",
       "42750       965.0                     data visualization playbook: revisiting the basics   NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The articles with no email/user interaction in the df dataframe\n",
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of unique articles that have no user interaction in the df dataframe\n",
    "df[df.isna().any(axis=1)]['article_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique articles that have at least one interaction is 714.\n",
      "The number of unique articles on the IBM platform is 1051.\n",
      "The number of unique users is 5148.\n",
      "The number of user-article interactions is 45993\n"
     ]
    }
   ],
   "source": [
    "unique_articles = df.article_id.nunique()\n",
    "print('The number of unique articles that have at least one interaction is {}.'.format(unique_articles))\n",
    "total_articles = df_content.article_id.nunique()\n",
    "print('The number of unique articles on the IBM platform is {}.'.format(total_articles))\n",
    "unique_users = df.email.nunique()\n",
    "print('The number of unique users is {}.'.format(unique_users))\n",
    "user_article_interactions = df[['email', 'article_id']].shape[0]\n",
    "print('The number of user-article interactions is {}'.format(user_article_interactions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` _In the cells below we find the most viewed `article_id`, as well as how often it was viewed. After talking to the company leaders, the `email_mapper` function was deemed a reasonable way to map users to ids. There were a small number of null values, and it was found that all of these null values likely belonged to a single user (which is how they are stored using the function below)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id\n",
       "1429.0    937\n",
       "1330.0    927\n",
       "1431.0    671\n",
       "1427.0    643\n",
       "1364.0    627\n",
       "Name: email, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many times each article is viewed\n",
    "df.groupby('article_id').count()['email'].sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id                                       528.0\n",
       "title                10 tips on using jupyter notebook\n",
       "email         7888dc37498447d0477be7ee2c4176543f5a6190\n",
       "Name: 1429, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The most viewed article\n",
    "df.loc[1429]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc_body           Homepage About membership Sign in Get started Homepage Roman Kierzkowski Blocked Unblo...\n",
       "doc_description    Jupyter Notebook (a.k.a iPython Notebook) is brilliant coding tool. It is ideal for do...\n",
       "doc_full_name                                                              10 tips on using Jupyter Notebook\n",
       "doc_status                                                                                              Live\n",
       "article_id                                                                                               528\n",
       "Name: 529, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The full information on the article NOTE: the 1 unit shift in article id between dataframes!!\n",
    "df_content.loc[529]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most viewed article_id in the dataset is 1429.0.\n",
      "The most viewed article in the dataset was viewed 937 times.\n"
     ]
    }
   ],
   "source": [
    "most_viewed_article_id = str(df.groupby('article_id').count()['email'].sort_values(ascending=False).index[0])\n",
    "print('The most viewed article_id in the dataset is {}.'.format(most_viewed_article_id))\n",
    "max_views = df.groupby('article_id').count()['email'].sort_values(ascending=False).iloc[0]\n",
    "print('The most viewed article in the dataset was viewed {} times.'.format(max_views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier data analysis and experimentation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                                                             title  user_id\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier data analysis and experimentation        1\n",
       "1      1314.0                                      healthcare python streaming application demo        2\n",
       "2      1429.0                                        use deep learning for image classification        3\n",
       "3      1338.0                                         ml optimization using cognitive assistant        4\n",
       "4      1276.0                                         deploy your python model as a restful api        5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map the user email to a user_id column and remove the email column\n",
    "\n",
    "def email_mapper():\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "# show header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you have everything right here! Nice job!\n"
     ]
    }
   ],
   "source": [
    "# Testing unit for the above defined variables\n",
    "\n",
    "sol_1_dict = {\n",
    "    '`50% of individuals have _____ or fewer interactions.`': median_val,\n",
    "    '`The total number of user-article interactions in the dataset is ______.`': user_article_interactions,\n",
    "    '`The maximum number of user-article interactions by any 1 user is ______.`': max_views_by_user,\n",
    "    '`The most viewed article in the dataset was viewed _____ times.`': max_views,\n",
    "    '`The article_id of the most viewed article is ______.`': most_viewed_article_id,\n",
    "    '`The number of unique articles that have at least 1 rating ______.`': unique_articles,\n",
    "    '`The number of unique users in the dataset is ______`': unique_users,\n",
    "    '`The number of unique articles on the IBM platform`': total_articles\n",
    "}\n",
    "\n",
    "# Test your dictionary against the solution\n",
    "t.sol_1_test(sol_1_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Rank\">Part II: Rank-Based Recommendations</a>\n",
    "\n",
    "This dataset does not contain ratings for whether a user liked an article or not.  We only know that a user has interacted with an article.  In these cases, the popularity of an article can really only be based on how often an article was interacted with.\n",
    "\n",
    "`1.` _The next function returns the **n** top articles ordered with most interactions at the top. The function is also tested below._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['use deep learning for image classification',\n",
       " 'insights from new york car accident reports']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the approach used in the function\n",
    "list(df.groupby('title').count()['user_id'].sort_values(ascending=False).index[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_articles(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top n article titles \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    top_articles = list(df.groupby('title').count()['user_id'].sort_values(ascending=False).index[:n])\n",
    "    # Return the top article titles from df \n",
    "    return top_articles \n",
    "\n",
    "def get_top_article_ids(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article tids\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    top_articles_ids = list(df.groupby('article_id').count()['user_id'].sort_values(ascending=False).index[:n])\n",
    "    # Return the top article ids\n",
    "    return top_articles_ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['use deep learning for image classification', 'insights from new york car accident reports', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model']\n",
      "[1429.0, 1330.0, 1431.0, 1427.0, 1364.0, 1314.0, 1293.0, 1170.0, 1162.0, 1304.0]\n"
     ]
    }
   ],
   "source": [
    "print(get_top_articles(10))\n",
    "print(get_top_article_ids(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your top_5 looks like the solution list! Nice job.\n",
      "Your top_10 looks like the solution list! Nice job.\n",
      "Your top_20 looks like the solution list! Nice job.\n"
     ]
    }
   ],
   "source": [
    "# Test the function by returning the top 5, 10, and 20 articles\n",
    "top_5 = get_top_articles(5)\n",
    "top_10 = get_top_articles(10)\n",
    "top_20 = get_top_articles(20)\n",
    "\n",
    "# Test each of the three lists from above\n",
    "t.sol_2_test(get_top_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"User-User\">Part III: User-User Based Collaborative Filtering</a>\n",
    "\n",
    "\n",
    "`1.` Reformat the `df` dataframe to be shaped with users as the rows and articles as the columns.  \n",
    "\n",
    "* Each `user` appears in each row once.\n",
    "\n",
    "* Each `article` shows up in only one `column`.  \n",
    "\n",
    "* **If a user has interacted with an article, a 1 is placed where the user-row meets for that article-column**.  It does not matter how many times a user has interacted with the article, all entries where a user has interacted with an article are **1**.  \n",
    "\n",
    "* **If a user has not interacted with an item, a zero is placed where the user-row meets for that article-column**. \n",
    "\n",
    "The tests are used to make sure the basic structure of the matrix matches what is expected by the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the user-article matrix with 1's and 0's\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df (pandas dataframe) - article_id, title, user_id are the columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item (nd array) - user item matrix \n",
    "    \n",
    "    Description:\n",
    "    Return a matrix with user ids as rows and article ids on the columns,\n",
    "    with 1 values where a user interacted with an article and a 0 otherwise.\n",
    "    '''\n",
    "    \n",
    "    # Create new column that keeps track of user_article interaction\n",
    "    df['interact'] = 1\n",
    "    # Transform df so that every user is on a row and every article corresponds to a column\n",
    "    user_item = df.groupby(['user_id', 'article_id'])['interact'].first().unstack()\n",
    "    # Fill in NaN with 0 in the user_item matrix\n",
    "    user_item.fillna(0, inplace = True)\n",
    "    \n",
    "    return user_item # return the user_item matrix \n",
    "\n",
    "user_item = create_user_item_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have passed our quick tests!  Please proceed!\n"
     ]
    }
   ],
   "source": [
    "# Tests: You should just need to run this cell.  Don't change the code.\n",
    "assert user_item.shape[0] == 5149, \"Oops!  The number of users in the user-article matrix doesn't look right.\"\n",
    "assert user_item.shape[1] == 714, \"Oops!  The number of articles in the user-article matrix doesn't look right.\"\n",
    "assert user_item.sum(axis=1)[1] == 36, \"Oops!  The number of articles seen by user 1 doesn't look right.\"\n",
    "print(\"You have passed our quick tests!  Please proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` _The function below takes a `user_id` and provide an ordered list of the most similar users to that user (from most similar to least similar). The returned result should not contain the provided `user_id`, as we know that each user is similar to him/herself. Because the results for each user here are binary, it (perhaps) makes sense to compute similarity as the dot product of two users. \n",
    "\n",
    "_We use the tests to test the function._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_users(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user_id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    similar_users - (list) an ordered list where the closest users (largest dot product users)\n",
    "                    are listed first\n",
    "    \n",
    "    Description:\n",
    "    Computes the similarity of every pair of users based on the dot product\n",
    "    Returns an ordered\n",
    "    \n",
    "    '''\n",
    "    # compute similarity of each user to the provided user\n",
    "    user_similarities = user_item.dot(user_item.loc[user_id])\n",
    "\n",
    "    # sort by similarity\n",
    "    sorted_similarities = user_similarities.sort_values(ascending=False)\n",
    "\n",
    "    # create list of just the ids\n",
    "    similars = list(sorted_similarities.index)\n",
    "   \n",
    "    # remove the own user's id\n",
    "    most_similar_users = similars[1:]\n",
    "       \n",
    "    return most_similar_users # return a list of the users in order from most to least similar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most similar users to user 1 are: [3933, 23, 3782, 203, 4459, 3870, 131, 4201, 46, 5041]\n",
      "The 5 most similar users to user 3933 are: [3933, 23, 3782, 203, 4459]\n",
      "The 3 most similar users to user 46 are: [4201, 3782, 23]\n"
     ]
    }
   ],
   "source": [
    "# Do a spot check of your function\n",
    "print(\"The 10 most similar users to user 1 are: {}\".format(find_similar_users(1)[:10]))\n",
    "print(\"The 5 most similar users to user 3933 are: {}\".format(find_similar_users(3933)[:5]))\n",
    "print(\"The 3 most similar users to user 46 are: {}\".format(find_similar_users(46)[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` _Now that we have a function that provides the most similar users to each user, we will want to use these users to find articles we can recommend.  The functions below return the articles we would recommend to each user._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_names(article_ids, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_ids - (list) a list of article ids\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the title column)\n",
    "    '''\n",
    "    article_names = [df[df['article_id'] == float(x)]['title'].unique()[0] for x in article_ids]\n",
    "    # Return the article names associated with list of article ids\n",
    "    return article_names \n",
    "\n",
    "\n",
    "def get_user_articles(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_ids - (list) a list of the article ids seen by the user\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the doc_full_name column in df_content)\n",
    "    \n",
    "    Description:\n",
    "    Provides a list of the article_ids and article titles that have been seen by a user\n",
    "    '''\n",
    "\n",
    "    article_ids = user_item.loc[user_id][user_item.loc[user_id] == 1].index.astype('str').to_list()\n",
    "    article_names = get_article_names(article_ids, df)\n",
    "    return article_ids, article_names # return the ids and names\n",
    "\n",
    "\n",
    "def user_user_recs(user_id, m):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    Users who are the same closeness are chosen arbitrarily as the 'next' user\n",
    "    \n",
    "    For the user where the number of recommended articles starts below m \n",
    "    and ends exceeding m, the last items are chosen arbitrarily\n",
    "    \n",
    "    '''\n",
    "    # articles_seen by user (we don't want to recommend these)\n",
    "    articles_seen = get_user_articles(user_id, user_item)[0]\n",
    "    # find the similar users\n",
    "    similar_users = find_similar_users(user_id)\n",
    "    \n",
    "    # list of recommended articles\n",
    "    recs = []\n",
    "    \n",
    "    for user in similar_users:\n",
    "        user_list = get_user_articles(user, user_item)[0]\n",
    "        recs_update = np.setdiff1d(user_list, articles_seen)\n",
    "        recs.extend(np.setdiff1d(recs_update, recs))\n",
    "     \n",
    "        if len(recs) >= m:\n",
    "            break\n",
    "    \n",
    "    return recs[:m] # return recommendations for this user_id    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recommender systems: approaches & algorithms',\n",
       " '1448    i ranked every intro to data science course on...\\nName: title, dtype: object',\n",
       " 'data tidying in data science experience',\n",
       " 'a tensorflow regression model to predict house values',\n",
       " '520    using notebooks with pixiedust for fast, flexi...\\nName: title, dtype: object',\n",
       " 'airbnb data for analytics: mallorca reviews',\n",
       " 'airbnb data for analytics: vancouver listings',\n",
       " 'analyze facebook data using ibm watson and watson studio',\n",
       " 'analyze accident reports on amazon emr spark',\n",
       " 'analyze energy consumption in buildings']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Results\n",
    "get_article_names(user_user_recs(1, 10)) # Return 10 recommendations for user 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, you passed all of our tests!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "# Test the functions here - No need to change this code - just run this cell\n",
    "assert set(get_article_names(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_article_names(['1320.0', '232.0', '844.0'])) == set(['housing (2015): united states demographic measures','self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_user_articles(20)[0]) == set(['1320.0', '232.0', '844.0'])\n",
    "assert set(get_user_articles(20)[1]) == set(['housing (2015): united states demographic measures', 'self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook'])\n",
    "assert set(get_user_articles(2)[0]) == set(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])\n",
    "assert set(get_user_articles(2)[1]) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis'])\n",
    "print(\"If this is all you see, you passed all of our tests!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` _Now we are going to improve the consistency of the **user_user_recs** function from above._\n",
    "\n",
    "* _Instead of arbitrarily choosing when we obtain users who are all the same closeness to a given user - choose the users that have the most total article interactions before choosing those with fewer article interactions._\n",
    "\n",
    "* _Instead of arbitrarily choosing articles from the user where the number of recommended articles starts below m and ends exceeding m, choose articles with the articles with the most total interactions before choosing those with fewer total interactions. This ranking should be what would be obtained from the **top_articles** function written earlier._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample user id\n",
    "user_id = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5148"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order the other users based on similarity\n",
    "neighbor_id = find_similar_users(user_id)\n",
    "len(neighbor_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record the similarity measure, i.e. the dot product with user_id \n",
    "similarity = [user_item.loc[neighbor].dot(user_item.loc[user_id]) for neighbor in neighbor_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of views for each user\n",
    "num_interactions = [df[df['user_id'] == x].shape[0] for x in neighbor_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary \n",
    "neighbors_df = {'neighbor_id': neighbor_id,\n",
    "               'similarity': similarity,\n",
    "               'num_interactions': num_interactions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from dictionary\n",
    "neighbors_df = pd.DataFrame(data=neighbors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbor_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>num_interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3691</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>12.0</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3782</td>\n",
       "      <td>12.0</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>11.0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3169</td>\n",
       "      <td>11.0</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighbor_id  similarity  num_interactions\n",
       "0         3691        28.0                33\n",
       "1           23        12.0               364\n",
       "2         3782        12.0               363\n",
       "3          170        11.0               116\n",
       "4         3169        11.0               114"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the output\n",
    "neighbors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbor_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>num_interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3691</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>12.0</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighbor_id  similarity  num_interactions\n",
       "0         3691        28.0                33\n",
       "1           23        12.0               364"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the values\n",
    "neighbors_df.sort_values(by=['similarity', 'num_interactions'], ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbor_id         72.0\n",
       "similarity           8.0\n",
       "num_interactions    49.0\n",
       "Name: 17, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the information of the user_id we started with\n",
    "neighbors_df.loc[user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3691, 23, 3782, 170, 3169, 49, 3764, 3697, 98, 256]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of the most simlar users\n",
    "neighbor_list = neighbor_id[:10]\n",
    "neighbor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get one member from the neighbors list\n",
    "user = neighbor_list[1]\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # get the articles seen by the similar user\n",
    "similar_seen = get_user_articles(user, user_item)[0]\n",
    "len(similar_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['108.0', '146.0', '158.0', '162.0']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the articles seen by user_id member\n",
    "articles_seen =  get_user_articles(user_id, user_item)[0]\n",
    "articles_seen[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the articles seen by user_id from neighbor's list\n",
    "# these are the articles to recommend\n",
    "articles_to_rec = np.setdiff1d(similar_seen, articles_seen)\n",
    "len(articles_to_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the final list of articles to recommend\n",
    "recs_ids = []\n",
    "# the articles seen by similar user to add to the recommended list\n",
    "# remove those articles already in the list\n",
    "articles_to_add = np.setdiff1d(articles_to_rec, recs_ids)\n",
    "len(articles_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000.0, 1014.0]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the next step we need article ids as float or integer\n",
    "articles_ids = [float(x) for x in articles_to_add]\n",
    "articles_ids[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1429.0, 1330.0]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the article ids\n",
    "df_reduced=df[df['article_id'].isin(articles_ids)]\n",
    "df_reduced.groupby('article_id').count()['title'].sort_values(ascending=False).index.to_list()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sorted_users(user_id, df=df, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int)\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "            1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "            \n",
    "    OUTPUT:\n",
    "    neighbors_df - (pandas dataframe) a dataframe with:\n",
    "                    neighbor_id - is a neighbor user_id\n",
    "                    similarity - measure of the similarity of each user to the provided user_id\n",
    "                    num_interactions - the number of articles viewed by the user - if a u\n",
    "                    \n",
    "    Other Details - sort the neighbors_df by the similarity and then by number of interactions where \n",
    "                    highest of each is higher in the dataframe\n",
    "     \n",
    "    '''\n",
    "    # order the other users based on similarity with member user_id\n",
    "    neighbor_id = find_similar_users(user_id)\n",
    "    # record the similarity measure, i.e. the dot product with user_id \n",
    "    similarity = [user_item.loc[neighbor].dot(user_item.loc[user_id]) for neighbor in neighbor_id]\n",
    "    # find the number of views/interactions for each user\n",
    "    num_interactions = [df[df['user_id'] == x].shape[0] for x in neighbor_id]\n",
    "    \n",
    "    # create a dataframe \n",
    "    neighbors_df = pd.DataFrame(data={'neighbor_id': neighbor_id,\n",
    "                                      'similarity': similarity,\n",
    "                                      'num_interactions': num_interactions})\n",
    "    # drop the row corresponding to the member user_id\n",
    "    neighbors_df.drop(user_id, axis = 0, inplace = True)\n",
    "    \n",
    "    # sort by similarity and num_interactions                 \n",
    "    neighbors_df.sort_values(by = ['similarity', 'num_interactions'], \n",
    "                             inplace=True, \n",
    "                             ascending=(False, False))   \n",
    "    \n",
    "    # Return the dataframe specified in the doc_string\n",
    "    return neighbors_df \n",
    "\n",
    "\n",
    "def user_user_recs_part2(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user by article id\n",
    "    rec_names - (list) a list of recommendations for the user by article title\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    * Choose the users that have the most total article interactions \n",
    "    before choosing those with fewer article interactions.\n",
    "\n",
    "    * Choose articles with the articles with the most total interactions \n",
    "    before choosing those with fewer total interactions. \n",
    "   \n",
    "    '''\n",
    "    # list of recommended articles by id, and by title\n",
    "    recs_ids = []\n",
    "    \n",
    "    # articles_seen by user (we don't want to recommend these)\n",
    "    articles_seen = get_user_articles(user_id, user_item)[0]\n",
    "    \n",
    "    # similar users with most article views\n",
    "    similar_users = get_top_sorted_users(user_id, df, user_item)\n",
    "    \n",
    "    for user in similar_users['neighbor_id'].values:\n",
    "        \n",
    "        # get the articles seen by the similar user\n",
    "        similar_seen = get_user_articles(user, user_item)[0]\n",
    "        \n",
    "        # remove the articles in articles_seen\n",
    "        articles_to_rec = np.setdiff1d(similar_seen, articles_seen)\n",
    "        \n",
    "        # remove the articles already added to the recs list\n",
    "        articles_to_add = np.setdiff1d(articles_to_rec, recs_ids)\n",
    "        \n",
    "        # rewrite the recommended article ids as float \n",
    "        articles_ids = [float(x) for x in articles_to_add]\n",
    "        \n",
    "        # sort the articles by popularity, i.e. number of views\n",
    "        df_red = df[df['article_id'].isin(articles_ids)]\n",
    "        sorted_articles=df_red.groupby('article_id').count()['title'].sort_values(ascending=False).index.to_list()\n",
    "       \n",
    "        # add the sorted article ids\n",
    "        recs_ids.extend(sorted_articles)\n",
    "        \n",
    "        # break when we have enough articles to recommend\n",
    "        if len(recs_ids) >= m:\n",
    "            break\n",
    "    \n",
    "    # retain the first m recommendations\n",
    "    recs = recs_ids[:m]\n",
    "    \n",
    "    # get the articles names\n",
    "    rec_names = get_article_names(recs, df)\n",
    "    \n",
    "    return recs, rec_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 recommendations for user 20 are the following article ids:\n",
      "[1330.0, 1427.0, 1364.0, 1170.0, 1162.0, 1304.0, 1351.0, 1160.0, 1354.0, 1368.0]\n",
      "\n",
      "The top 10 recommendations for user 20 are the following article names:\n",
      "['insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'model bike sharing data with spss', 'analyze accident reports on amazon emr spark', 'movie recommender system with spark machine learning', 'putting a human face on machine learning']\n"
     ]
    }
   ],
   "source": [
    "# Quick spot check - don't change this code - just use it to test your functions\n",
    "rec_ids, rec_names = user_user_recs_part2(20, 10)\n",
    "print(\"The top 10 recommendations for user 20 are the following article ids:\")\n",
    "print(rec_ids)\n",
    "print()\n",
    "print(\"The top 10 recommendations for user 20 are the following article names:\")\n",
    "print(rec_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` _Based on the functions from above to we fill in the solutions to the dictionary below. Then test the dictionary against the solution. The code needed to answer each of the following comments below is provided._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests with a dictionary of results\n",
    "\n",
    "# Find the user that is most similar to user 1 \n",
    "user1_most_sim = get_top_sorted_users(1, df, user_item).loc[0]['neighbor_id']\n",
    "# Find the 10th most similar user to user 131\n",
    "user131_10th_sim = get_top_sorted_users(131, df, user_item).loc[10]['neighbor_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3933.0 242.0\n"
     ]
    }
   ],
   "source": [
    "print(user1_most_sim, user131_10th_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This all looks good!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "# Dictionary Test Here\n",
    "sol_5_dict = {\n",
    "    'The user that is most similar to user 1.': user1_most_sim, \n",
    "    'The user that is the 10th most similar to user 131': user131_10th_sim,\n",
    "}\n",
    "\n",
    "t.sol_5_test(sol_5_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6.` _If we were given a new user, which of the above functions would you be able to use to make recommendations?  Explain.  Can you think of a better way we might make recommendations?  Use the cell below to explain a better method for new users._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For a new use we recommend the most popular articles on the website, through `get_top_articles` and `get_top_article_ids` functions, as we don't have any information about user's preferences.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`7.` _Using the existing functions, we provide the top 10 recommended articles we would provide for a new user below. Test the function against the standard solution._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user = '0.0'\n",
    "\n",
    "# What would your recommendations be for this new user '0.0'?  As a new user, they have no observed articles.\n",
    "# Provide a list of the top 10 article ids you would give to \n",
    "new_user_recs = get_top_article_ids(10, df) # Your recommendations here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite recommendations as a set of strings\n",
    "new_user_recs = [str(x) for x in new_user_recs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "assert set(new_user_recs) == set(['1314.0','1429.0','1293.0','1427.0',\n",
    "                                  '1162.0','1364.0','1304.0','1170.0','1431.0','1330.0']), \"Oops! It makes sense that in this case we would want to recommend the most popular articles, because we don't know anything about these users.\"\n",
    "\n",
    "print(\"That's right!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Content-Recs\">Part IV: Content Based Recommendations</a>\n",
    "\n",
    "Another method we might use to make recommendations is to perform a ranking of the highest ranked articles associated with some term. We could consider content to be the `doc_body`, `doc_description`, or `doc_full_name`.  There isn't one way to create a content based recommendation, especially considering that each of these columns hold content related information.  \n",
    "\n",
    "`1.` _We will create a content based recommender based on `doc_description` column.  This will be done Since there isn't one right answer for this recommendation tactic, no test functions are provided. \n",
    "\n",
    "* write a recommender function that takes in an article_id as an argument and outputs the articles similar to it based on the article description\n",
    "\n",
    "The input values are currently set with one idea in mind that may use to make content based recommendations.  One additional idea is that you might want to choose the most popular recommendations that meet your 'content criteria', but again, there is a lot of flexibility in how you might make these recommendations.\n",
    "\n",
    "### This part is NOT REQUIRED to pass this project.  However, you may choose to take this on as an extra way to show off your skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['article_id', 'title', 'user_id', 'interact'], dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the data\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id    float64\n",
       "title          object\n",
       "user_id         int64\n",
       "interact        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data types in df\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['doc_body', 'doc_description', 'doc_full_name', 'doc_status',\n",
       "       'article_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the data\n",
    "df_content.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc_body           object\n",
       "doc_description    object\n",
       "doc_full_name      object\n",
       "doc_status         object\n",
       "article_id          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data types in df_content\n",
    "df_content.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc_body            object\n",
       "doc_description     object\n",
       "doc_full_name       object\n",
       "doc_status          object\n",
       "article_id         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the data type for article_id to float\n",
    "df_content['article_id'] = df_content['article_id'].astype(float)\n",
    "\n",
    "# check the outcome\n",
    "df_content.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VID...</td>\n",
       "      <td>Detect bad readings in real time using Python and Streaming Analytics.</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streaming Analytics</td>\n",
       "      <td>Live</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n * kaggle.com\\r\\n\\r\\nCommunicating data s...</td>\n",
       "      <td>See the forest, see the trees. Here lies the challenge in both performing and presenti...</td>\n",
       "      <td>Communicating data science: A guide to presenting your work</td>\n",
       "      <td>Live</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    doc_body                                                                            doc_description                                                doc_full_name doc_status  article_id\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VID...                     Detect bad readings in real time using Python and Streaming Analytics.   Detect Malfunctioning IoT Sensors with Streaming Analytics       Live         0.0\n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n * kaggle.com\\r\\n\\r\\nCommunicating data s...  See the forest, see the trees. Here lies the challenge in both performing and presenti...  Communicating data science: A guide to presenting your work       Live         1.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a closer look at the data\n",
    "df_content.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc_body           OFFLINE-FIRST IOS APPS WITH SWIFT & PART 1: THE DATASTOREJason H. Smith / January 25, ...\n",
       "doc_description    Apple's sample app, Food Tracker, taught you iOS. Now, take it further and sync data b...\n",
       "doc_full_name                       Offline-First iOS Apps with Swift & Cloudant Sync; Part 1: The Datastore\n",
       "doc_status                                                                                              Live\n",
       "article_id                                                                                              10.0\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate a particular data point\n",
    "df_content.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OFFLINE-FIRST IOS APPS WITH SWIFT & PART 1: THE DATASTOREJason H. Smith / January 25, 2016This walk-through is a sequel to Apple’s well-known iOS programmingintroduction, Start Developing iOS Apps (Swift) . Apple’s introduction walks us through the process of building the UI, data,and logic of an example food tracker app, culminating with a section on datapersistence: storing the app data as files in the iOS device.This series picks up where that document leaves off: syncing data betweendevices, through the cloud, with an offline-first design. You will achieve thisusing open source tools and the free IBM Cloudant service.This document is the first in the series, showing you how to use the CloudantSync datastore, CDTDatastore , for FoodTracker on the iOS device. Subsequent posts will cover syncing to thecloud and other advanced features such as accounts and data management.TABLE OF CONTENTS 1. Getting Started 2. CocoaPods 1. Learning Objectives     2. Install CocoaPods on your Mac     3. Install Cloudant Sync using CocoaPods     4. Change from a Project to a Workspace         3. Compile with Cloudant Sync 1. Learning Objectives     2. Create the CDTDatastore Bridging Header     3. Check the Build         4. Store Data Locally with Cloudant Sync 1. Offline First     2. Learning Objectives     3. The Cloudant Document Model     4. Design Plan     5. Remove NSCoding     6. Initialize the Cloudant Sync Datastore     7. Side Note: Deleting the Datastore in the iOS Simulator     8. Implement Storing and Querying Meals     9. Create Sample Meals in the Datastore         5. Conclusion 6. Download This ProjectGETTING STARTEDThe FoodTracker main screenThese lessons assume that you have completed the FoodTracker app from Apple’s walk-through. First, complete that walk-through. It will teach youthe process of beginning an iOS app and it will end with the chapter, Persist Data . Download the sample project from the final lesson (the “Download File” linkat the bottom of the page).Extract the zip file, Start-Dev-iOS-Apps-10.zip , browse into its folder with Finder, and double-click FoodTracker.xcodeproj . That will open the project in Xcode. Run the app (Command-R) and confirm thatit works correctly. If everything is in order, proceed with this document.COCOAPODSThe first step is to install CocoaPods which will allow you to quickly and easily use open source packages in your iOSapps. You will use the CocoaPods repository to integrate the Cloudant Sync Datastore library, called CDTDatastore .LEARNING OBJECTIVESAt the end of the lesson, you’ll be able to: 1. Install CocoaPods on your Mac 2. Use CocoaPods to download and integrate CDTDatastore with FoodTrackerINSTALL COCOAPODS ON YOUR MACThe CocoaPods web site has an excellent page, Getting Started , which covers installing and upgrading. For your purposes, you will use themost simple approach to installation, the command-line gem program.To install CocoaPods 1. Open the Terminal application 1. Click the Spotlight icon (a magnifying glass) in the Mac OS task bar     2. Type “terminal” in the Spotlight prompt, and press return         2. In Terminal, type this command:gem install cocoapods            Note , if you receive an error message and the CocoaPods gem does not install,    try this instead:        sudo gem install cocoapods             3. Confirm that CocoaPods is installed with this command:        pod --version            You should see the CocoaPods version displayed in Terminal:        0.39.0            INSTALL CLOUDANT SYNC USING COCOAPODSTo install CDTDatastore as a dependency, create a Podfile , a simple configuration files which tell CocoaPods which packages this projectneeds.To create a Podfile 1. Choose File > New > File… (or press Command-N) 2. On the left side of the dialog that appears, under “iOS”, select Other. 3. Select Empty, and click Next. 4. In the Save As field, type Podfile . 5. The save location (“Where”) defaults to your project directory.The Group option defaults to your app name, FoodTracker.        In the Targets section, make sure both your app and the tests for your app    are not selected.         6. Click Create. Xcode will create a file called Podfile which is open in the Xcode editor.Next, configure CDTDatastore in the Podfile.To configure the Podfile 1. In Podfile , add the following codeplatform :ios, \\'9.1\\'    pod \"CDTDatastore\", \\'~> 1.0.0\\'         2. Choose File > Save (or press Command-S)With your Podfile in place, you can now use CocoaPods to install theCDTDatastore pod.To install CDTDatastore 1. Open Terminal 2. Change to your project directory, the directory containing your new Podfile.    For example,# Your \\'cd\\' change to the folder you use.    cd \"FoodTracker - Persist Data\"             3. Type this command. Note, *this may take a few minutes to complete .        pod install --verbose            You will see colorful output from CocoaPods in the terminal.CHANGE FROM A PROJECT TO A WORKSPACEBecause you are now integrating FoodTracker with the third-party CDTDatastorelibrary, your project is now a group of projects combined into one useful whole. XCode supports this, and CocoaPodshas already prepared you for this transition by creating FoodTracker.xcworkspace for you—a workspace encompassing both FoodTracker and CDTDatastore.To change to your project workspace 1. Choose File > Close Window (or press Command-W). 2. Choose File > Open (or press Command-O). 3. Select FoodTracker.xcworkspace and click Open.You will see a similar XCode view as before, but notice that you now have twoprojects now.Note , when you build or run the app, you may see compiler warnings fromCDTDatastore code and its dependencies. You can safely ignore these warnings.Checkpoint: Run your app. The app should behave exactly as before. Now you know that everything is in itsplace and working correctly.COMPILE WITH CLOUDANT SYNCYour next step is to compile FoodTracker along with CDTDatastore . You will not change any major FoodTracker code yet; however, this willconfirm that CDTDatastore and FoodTracker integrate and compile correctly.LEARNING OBJECTIVESAt the end of the lesson, you’ll be able to create a bridging header to link Swift and Objective-C code.CREATE THE CDTDATASTORE BRIDGING HEADERCDTDatastore is written in Objective-C. FoodTracker is a Swift project.Currently, the best way to integrate these projects together is with a bridging header . The bridging header, CloudantSync-Bridging-Header.h , will tell Xcode to compile CDTDatastore into the final app.To create a header file 1.  Choose File > New > File (or press Command-N) 2.  On the left side of the dialog that appears, under “iOS”, select Source. 3.  Select Header File, and click Next. 4.  In the Save As field, type CloudantSync-Bridging-Header . 5.  Click the down-arrow expander button to the right of the “Save As” field.     This will display the file system tree of the project. 6.  Click the FoodTracker folder. 7.  Confirm that the Group option defaults to your app name, FoodTracker. 8.  In the Targets section, check the FoodTracker target. 9.  Click Create. Xcode will create and open a file called CloudantSync-Bridging-Header.h . 10. Under the line which says #define CloudantSync_Bridging_Header_h , insert the following code:#import <CloudantSync.h>           11. Choose File > Save (or press Command-S)The header file contents are done. But, despite its name, this file is not yet a bridging header as far as Xcode knows. The final step is to tell Xcode that this file willserve as the Objective-C bridging header.To assign a project bridging header 1. Enter the Project Navigator view by clicking the upper-left folder icon (or    press Command-1). 2. Select the FoodTracker project in the Navigator. 3. Under Project, select the FoodTracker project. (It has a blue icon). 4. Click “Build Settings”. 5. Click All to show all build settings 6. In the search bar, type “bridging header.” You should see Swift Compiler – Code Generation and inside it, Objective-C Bridging Header .         7. Double-click the empty space in the “FoodTracker” column, in the row    “Objective-C Bridging Header”. 8. A prompt window will pop up. Input the following:        FoodTracker/CloudantSync-Bridging-Header.h                     9. Press returnYour bridging header is done! Xcode should look like this:CHECK THE BUILDCheckpoint: Run your app. This will confirm that the code compiles and runs. While you have not changedany user-facing app code, you have begun the first step to Cloudant Sync bycompiling CDTDatastore into your project.STORE DATA LOCALLY WITH CLOUDANT SYNCWith CDTDatastore compiled and connected to FoodTracker, the next step is toreplace the NSCoder persistence system with CDTDatastore. Currently, in MealTableViewController.swift , during initialization, the encoded array of meals is loaded from localstorage. When you add or change a meal, the entire meals array is encoded and stored on disk.You will replace that system with a document-based architecture—in other words,each meal will be one record (called a “document” or simply “doc”) in theCloudant Sync datastore.Keep in mind, this first step of using Cloudant Sync does not use the Internet at all . The first goal is simply to store app data locally, in CDTDatastore. Afterthat works correctly, you will add the ability to sync with Cloudant.OFFLINE FIRSTThis is the offline-first architecture , with Internet access being optional to use the app. All data operations areon the local device. If the device has an Internet connection, then the app willsync its data with Cloudant—covered in future posts in this series.LEARNING OBJECTIVESAt the end of the lesson, you’ll be able to: 1. Understand the Cloudant document model: 1. Key-value storage for simple data types     2. Attachment storage for binary data     3. The document ID and revision ID         2. Store meals in the Cloudant Sync datastore 3. Query for meals in chronological order, from the datastoreTHE CLOUDANT DOCUMENT MODELLet’s begin with a discussion of Cloudant basics. The document is the primary data model of the Cloudant database, not only CDTDatastore foriOS, but also for Android, the Cloudant hosted database, and even the opensource Apache CouchDB database.A document, often called a doc , is a set of key-value data. Do not think, “Microsoft Office document”; think“JSON object.” A document is a JSON object: keys (strings) can have values:Ints, Doubles, Bools, Strings, as well as nested Arrays and Dictionaries.Documents can also contain binary blobs, called attachments . You can add, change, or remove attachments in a very similar way as you wouldadd, change, or remove key-value data in a doc.All documents always have two pieces of metadata used to manage them. The document ID (sometimes called _id or simply id ) is a unique string identifying the doc. You use the ID to read, and write aspecific document. When you create a document, you may omit the _id value, in which case Cloudant will automatically generate a unique ID for thedocument.The revision ID (sometimes called _rev or revision ) is a string generated by the datastore which tracks when the doc changes. Therevision ID is mostly used internally by the datastore, especially to facilitatereplication. In practice, you need to remember the basics about revisions : * The revision ID changes every time you update a document. * When you update a document, you provide the current revision ID to the   datastore, and the datastore will return to you the new revision ID of the new document. * When you create a document, you do not provide a revision ID, since there is no such “current” document.Finally, note that deleting a document is actually an update, with metadata setto indicate deletion, called a tombstone . Since a delete is an update just like any other, the deleted document willhave its own revision ID. The tombstones are necessary for replication:replicating a tombstone from one database to another will cause doc to bedeleted in both databases. As far as your app is concerned, it can consider thedocument deleted).DESIGN PLANWith this in mind, consider: how will the sample meals that are pre-loaded intothe app work? At first, you might think to create meal documents whenFoodTracker starts. That will work correctly the first time the user runs theapp; however, if the user changes or deletes the sample meals, those changes must persist . For example, if the user deletes the sample meals and then restarts the applater, those meals must remain deleted.To support this requirement, you will use document tombstones . This will be the basic design: * Each meal will be represented by a single document. User-created meals will   have an automatically-generated document ID; but sample meals will have   hard-coded document IDs: “meal1”, “meal2”, and “meal3”.// An example meal document:   {       \"_id\": \"meal1\",       \"name\": \"Caprese Salad\",       \"rating\": 4,       \"created_at\": \"2016-01-03T02:15:49.727Z\"   }          * Sample meals have a hard-coded docId . Just before creating a sample meal, first try to fetch the meal by ID. * If CDTDatastore returns a meal doc, that means it has already been      created. Do nothing .    * If CDTDatastore returns a \"not_found\" error, that means the meal has never been created. Proceed with doc creation .    * If CDTDatastore returns a different error, that means the meal has been      created and then deleted. Do nothing .      Now, you can put this understanding into practice by transitioning to CloudantSync for local app data storage.REMOVE NSCODINGBegin cleanly by removing the current NSCoding system from the model and thetable view controller.To remove NSCoding from the model 1. Open Meal.swift 2. Find the class declaration, which saysclassMeal: NSObject, NSCoding{             3. Remove the word NSCoding and also the comma before it, making the new class declaration look like    this:        classMeal: NSObject{             4. Delete the comment line, // MARK: NSCoding . 5. Delete the method below that, encodeWithCoder(_:) . 6. Delete the method below that, init?(_:) .Next, remove NSCoding from the table view controller.To remove NSCoding from the table view controller 1. Open MealTableViewController.swift 2. Find the method viewDidLoad() , and delete the comment beginning // Load any saved meals and also the if/else code below it:// Load any saved meals, otherwise load sample data.iflet savedMeals = loadMeals() {        meals += savedMeals    } else {        // Load the sample data.        loadSampleMeals()    }             3. Delete the method loadSampleMeals() , which is immediately beneath the viewDidLoad() method. 4. Find the method tableView(_:commitEditingStyle:forRowAtIndexPath:) and delete the line of code saveMeals() . 5. Find the method unwindToMealList(_:) and delete its last two lines of code: a comment, and a call to saveMeals() .        // Save the meals.    saveMeals()             6. Delete the comment line, // MARK: NSCoding 7. Delete the method below that, saveMeals() . 8. Delete the method below that, loadMeals() .Checkpoint: Run your app. The app will obviously lose some functionality: loading stored meals, andcreating the first three sample meals; although you can still create, edit, andremove meals (but they will not persist if you quit the app). That is okay. Inthe next step, you will restore these functions using Cloudant Sync instead.INITIALIZE THE CLOUDANT SYNC DATASTORENow you will add loading and saving back to the app, using the Cloudant Syncdatastore. A meal will be a document, with its name and rating stored askey-value data, and its photo stored as an attachment. Additionally, you willstore a creation timestamp, so that you can later sort the meals in the orderthey were created.Begin with the Meal model, the file Meal.swift . You will add a new initialization method which can create a Meal object froma document. In other words, the init() method will set the meal name and rating from the document key-value data; andit will set the meal photo from the document attachment.Representing a Meal as a Cloudant document requires few changes besides theinitialization function. The only change to the the actual model is to addvariables for the underlying document ID, and the creation time. By rememberinga meal’s document ID, you will be able to change that doc when the user changesthe meal (e.g. by changing its rating, its name, or its photo). And by storingits creation time, you can later query the database for meals in the order thatthe user created them.To add Cloudant Sync datastore support 1. Open Meal.swift 2. In Meal.swift , in the section MARK: Properties , append these lines so that the variable declarations look like this:// MARK: Propertiesvar name: Stringvar photo: UIImage?    var rating: Int// Data for Cloudant Syncvar docId: String?    var createdAt: NSDate         3. In Meal.swift , edit the init?(_:photo:rating:) method to accept docId as a final argument, and to set the docId and createdAt properties . When you are finished, the method will look like this:        init?(name: String, photo: UIImage?, rating: Int, docId: String?) {        // Initialize stored properties.self.name = name        self.photo = photo        self.rating = rating        self.docId = docId        self.createdAt = NSDate()            super.init()            // Initialization should fail if there is no name or if the// rating is negative.if name.isEmpty || rating < 0 {            returnnil        }    }            Now add a convenience initializer. This initializer will use a givenCDTDatastore document to create a Meal object.To create a convenience initializer 1. Open Meal.swift 2. In Meal.swift, below the method init?(_:photo:rating:docId:) , add the following code:requiredconvenienceinit?(aDoc doc:CDTDocumentRevision) {        iflet body = doc.body {            let name = body[\"name\"] as! Stringlet rating = body[\"rating\"] as! Intvar photo: UIImage? = niliflet photoAttachment = doc.attachments[\"photo.jpg\"] {                photo = UIImage(                  data: photoAttachment.dataFromAttachmentContent())            }                self.init(name:name, photo:photo, rating:rating,                      docId:doc.docId)        } else {            print(\"Error initializing meal from document: \\\\(doc)\")            returnnil        }    }            That’s it for the model. The Meal class now tracks its underlying document IDand creation time; and it supports convenient initialization directly from ameal document.Since the Meal model initializer has a new docId: String? parameter, you will need to update the one bit of code which initializes Mealobjects, in the Meal view controller.To update the meal view controller 1. Open MealViewController.swift 2. In MealViewController.swift , find the function prepareForSegue(_:sender:) and change the last section of code to (dd , docId: docId ):// Set the meal to be passed to MealTableViewController after the// unwind segue.let docId = meal?.docId    meal = Meal(name: name, photo: photo, rating: rating, docId: docId)            Now the model has been updated to work from Cloudant Sync documents.Checkpoint: Run your app. The app should build successfully. This will confirm that all changes areworking together harmoniously. Of course, the app behavior is obviouslyincomplete, which you will correct in the next steps.All that remains is to use the datastore from the Meal table view controller.Begin by initializing the datastore and data.To initialize the datastore 1. Open MealTableViewController.swift 2. In MealTableViewController.swift , in the section MARK: Properties , append these lines so that the variable declarations look like this:// MARK: Propertiesvar meals = [Meal]()    var datastoreManager: CDTDatastoreManager?    var datastore: CDTDatastore?             3. In MealTableViewController.swift , append the following code at the end of the method viewDidLoad() :        // Initialize the Cloudant Sync local datastore.    initDatastore()            Now write the initialization function. Begin by creating a code marker for thenew Cloudant Sync datastore methods.To create a code marker for your code 1. Open MealTableViewController.swift 2. In MealTableViewController.swift , find the last method in the class, unwindToMealList(_:) 3. Below that method, add the following:// MARK: Datastore        This will be the section of the code where you implement all Cloudant Syncdatastore functionality.To implement datastore initialization , in MealTableViewController.swift , append the following code in the section MARK: Datastore :funcinitDatastore() {    let fileManager = NSFileManager.defaultManager()    let documentsDir = fileManager.URLsForDirectory(.DocumentDirectory,        inDomains: .UserDomainMask).last!    let storeURL = documentsDir.URLByAppendingPathComponent(\"foodtracker-meals\")    let path = storeURL.path    do {        datastoreManager = tryCDTDatastoreManager(directory: path)        datastore = try datastoreManager!.datastoreNamed(\"meals\")    } catch {        fatalError(\"Failed to initialize datastore: \\\\(error)\")    }}SIDE NOTE: DELETING THE DATASTORE IN THE IOS SIMULATORSometimes during development, you may want to delete the datastore and startover. There are several ways to do this, for example, by deleting the app fromthe simulated device.However, here is a quick command you can paste into the terminal. It will removethe Cloudant Sync database. When you restart the app, the app will initialize anew datastore and behave as if this was its first time to run. For example, itwill re-create the sample meals again.To delete the datastore from the iOS Simulatorrm -i -rv $HOME/Library/Developer/CoreSimulator/Devices/*/data/Containers/Data/Application/*/Documents/foodtracker-mealsThis command will prompt you to remove the files. If you are confident that thecommand is working correct, you can omit the -i option.IMPLEMENT STORING AND QUERYING MEALSWith the datastore initialized, you need to write methods to store and retrievemeal documents. This is the cornerstone of your project. With a few methods tointeract with the datastore, you will enjoy all the benefits the Cloudant Syncdatastore brings: offline-first operation and cloud syncing.For FoodTracker, you will have two primary ways of persisting meals in thedatastore: creating meals and updating meals. Each of these will have its ownmethod, but the methods will share some common code to populate a meal documentwith the correct data. Begin by writing this method. Given a Meal object and aCloudant document, it will copy all of the meal data to the document, so thatthe latter can be created or updated as needed.To implement populating a meal document 1. Open MealTableViewController.swift 2. In MealTableViewController.swift , in the section MARK: Datastore , append a new method:funcpopulateRevision(meal: Meal, revision: CDTDocumentRevision?) {       // Populate a document revision from a Meal.let rev: CDTDocumentRevision = revision           ?? CDTDocumentRevision(docId: meal.docId)       rev.body[\"name\"] = meal.name       rev.body[\"rating\"] = meal.rating           // Set created_at as an ISO 8601-formatted string.let dateFormatter = NSDateFormatter()       dateFormatter.locale = NSLocale(localeIdentifier: \"en_US_POSIX\")       dateFormatter.timeZone = NSTimeZone(abbreviation: \"GMT\")       dateFormatter.dateFormat = \"yyyy-MM-dd\\'T\\'HH:mm:ss.SSS\\'Z\\'\"let createdAtISO = dateFormatter.stringFromDate(meal.createdAt)       rev.body[\"created_at\"] = createdAtISO           iflet data = UIImagePNGRepresentation(meal.photo!) {           let attachment = CDTUnsavedDataAttachment(data: data,               name: \"photo.jpg\", type: \"image/jpg\")           rev.attachments[attachment.name] = attachment       }    }            Next, implement the method to create new meal documents. Note that sample mealswill have hard-coded document IDs, so that you can detect if they have alreadybeen created or not. User-created meals will have no particular doc ID.To implement meal document creation 1. In MealTableViewController.swift , in the section MARK: Datastore , append a new method:// Create a meal. Return true if the meal was created, or false if// creation was unnecessary.funccreateMeal(meal: Meal) -> Bool {       // User-created meals will have docId == nil. Sample meals have a// string docId. For sample meals, look up the existing doc, with// three possible outcomes://   1. No exception; the doc is already present. Do nothing.//   2. The doc was created, then deleted. Do nothing.//   3. The doc has never been created. Create it.iflet docId = meal.docId {           do {               try datastore!.getDocumentWithId(docId)               print(\"Skip \\\\(docId) creation: already exists\")               returnfalse           } catchlet error asNSError {               if (error.userInfo[\"NSLocalizedFailureReason\"] as? String                       != \"not_found\") {                   print(\"Skip \\\\(docId) creation: already deleted by user\")                   returnfalse               }                   print(\"Create sample meal: \\\\(docId)\")           }       }           let rev = CDTDocumentRevision(docId: meal.docId)       populateRevision(meal, revision: rev)           do {           let result = try datastore!.createDocumentFromRevision(rev)           print(\"Created \\\\(result.docId)\\\\(result.revId)\")       } catch {           print(\"Error creating meal: \\\\(error)\")       }           returntrue    }            Now you are ready to write the update method. Note that “deleting” a Cloudantdocument is in fact a type of update . The update method will accept a Bool parameter indicating whether to deletethe document or not. However, to keep the rest of the code simple, you willwrite one-line convenience methods deleteMeal(_:) and updateMeal(_:) to set the deletion flag automatically.To implement deleting and updating meal documents 1. In MealTableViewController.swift , in the section MARK: Datastore , append the two convenience methods and then the full implementation.funcdeleteMeal(meal: Meal) {        updateMeal(meal, isDelete: true)    }        funcupdateMeal(meal: Meal) {        updateMeal(meal, isDelete: false)    }        funcupdateMeal(meal: Meal, isDelete: Bool) {        guardlet docId = meal.docId else {            print(\"Cannot update a meal with no document ID\")            return        }            let label = isDelete ? \"Delete\" : \"Update\"print(\"\\\\(label)\\\\(docId): begin\")            // First, fetch the current document revision from the DB.var rev: CDTDocumentRevisiondo {            rev = try datastore!.getDocumentWithId(docId)            populateRevision(meal, revision: rev)        } catch {            print(\"Error loading meal \\\\(docId): \\\\(error)\")            return        }            do {            var result: CDTDocumentRevisionif (isDelete) {                result = try datastore!.deleteDocumentFromRevision(rev)            } else {                result = try datastore!.updateDocumentFromRevision(rev)            }                print(\"\\\\(label)\\\\(docId) ok: \\\\(result.revId)\")        } catch {            print(\"Error updating \\\\(docId): \\\\(error)\")            return        }    }            Your app can now create, update, and delete meal docs. To complete this feature,these methods must be integrated with UI. When the user saves or deletes a meal,the controller must run these methods.To create and update meals 1. In MealTableViewController.swift , in the method unwindToMealList(_:) , modify the method body so that it calls updateMeal() or createMeal() as appropriate. The code will look as follows:iflet selectedIndexPath = tableView.indexPathForSelectedRow {        // Update an existing meal.        meals[selectedIndexPath.row] = meal        tableView.reloadRowsAtIndexPaths([selectedIndexPath], withRowAnimation: .None)        updateMeal(meal)    } else {        // Add a new meal.let newIndexPath = NSIndexPath(forRow: meals.count, inSection: 0)        meals.append(meal)        tableView.insertRowsAtIndexPaths([newIndexPath], withRowAnimation: .Bottom)        createMeal(meal)    }             2. In the method tableView(_:commitEditingStyle:forRowAtIndexPath) , insert a call to deleteMeal(_:) for the .Delete editing event. The code will look as follows.        if editingStyle == .Delete {        // Delete the row from the data sourcelet meal = meals[indexPath.row]        deleteMeal(meal)        meals.removeAtIndex(indexPath.row)        tableView.deleteRowsAtIndexPaths([indexPath],            withRowAnimation: .Fade)            The final thing to write is the code to query for meals in the datastore. Thiscode has two parts: initializing an index during app startup (to query bytimestamp), and of course the code to query that index.To support querying meals by timestamp 1. In MealTableViewController.swift , in the method initDatastore() , append this code:datastore?.ensureIndexed([\"created_at\"], withName: \"timestamps\")        // Everything is ready. Load all meals from the datastore.    loadMealsFromDatastore()             2. In MealTableViewController.swift , in the section MARK: Datastore , append this method:        funcloadMealsFromDatastore() {        let query = [\"created_at\": [\"$gt\":\"\"]]        let result = datastore?.find(query, skip: 0, limit: 0, fields:nil, sort: [[\"created_at\":\"asc\"]])        guard result != nilelse {            print(\"Failed to query for meals\")            return        }            meals.removeAll()        result!.enumerateObjectsUsingBlock({ (doc, idx, stop) -> Voidiniflet meal = Meal(aDoc: doc) {                self.meals.append(meal)            }        })    }            That’s it! The most intricate part of your code is finished.CREATE SAMPLE MEALS IN THE DATASTORENow is time to create sample meal documents during app startup. This method willrun every time the app initializes. For each sample meal, it will call createMeal(_:) which will either create the documents or no-op, as needed.To create sample meals during app startup 1. In MealTableViewController.swift , in the section MARK: Datastore , add a new method:funcstoreSampleMeals() {        let photo1 = UIImage(named: \"meal1\")!        let photo2 = UIImage(named: \"meal2\")!        let photo3 = UIImage(named: \"meal3\")!            let meal1 = Meal(name: \"Caprese Salad\", photo: photo1, rating: 4,            docId: \"sample-1\")!        let meal2 = Meal(name: \"Chicken and Potatoes\", photo: photo2, rating: 5,            docId:\"sample-2\")!        let meal3 = Meal(name: \"Pasta with Meatballs\", photo: photo3, rating: 3,            docId:\"sample-3\")!            // Hard-code the createdAt property to get consistent revision IDs. That way, devices that share// a common cloud database will not generate conflicts as they sync their own sample meals.let comps = NSDateComponents()        comps.day = 1        comps.month = 1        comps.year = 2016        comps.timeZone = NSTimeZone(abbreviation: \"GMT\")        let newYear = NSCalendar.currentCalendar()            .dateFromComponents(comps)!            meal1.createdAt = newYear        meal2.createdAt = newYear        meal3.createdAt = newYear            createMeal(meal1)        createMeal(meal2)        createMeal(meal3)    }             2. In MealTableViewController.swift , in the method initDatastore() , insert a call to storeSampleMeals() before the code initializing the index. The final lines of the method will    look as follows:           storeSampleMeals()       datastore?.ensureIndexed([\"created_at\"], withName: \"timestamps\")           // Everything is ready. Load all meals from the datastore.       loadMealsFromDatastore()    }            Checkpoint: Run your app. The app should behave exactly as it did at the beginning of this project.CONCLUSIONCongratulations! While the app remains unchanged superficially, you have made avery powerful upgrade to FoodTracker’s most important aspect: its data. You havetransformed the data layer from a minimal, unexceptional side note to become aflexible, powerful database. This database can be queried, searched, scaled, andreplicated between devices and through the cloud.The next update of this series will cover replicating this data to the cloudusing IBM Cloudant. Indeed, implementing cloud syncing is much simpler than thework from this lesson. You have completed laying the foundation!DOWNLOAD THIS PROJECTTo see the completed sample project for this lesson, download the file and viewit in Xcode.Download FileSHARE THIS: * Click to email this to a friend (Opens in new window) * Click to share on Twitter (Opens in new window) * Click to share on LinkedIn (Opens in new window) * Share on Facebook (Opens in new window) * Click to share on Reddit (Opens in new window) * Click to share on Pocket (Opens in new window) * Tagged: cloudant / iOS / Mobile / swift Please enable JavaScript to view the comments powered by Disqus. blog comments powered by Disqus * SUBSCRIBE TO BLOG UPDATES   Enter your email address to subscribe to this blog and receive notifications   of new posts by email.      Email Address             * CATEGORIES    * Analytics    * Cloudant    * Community    * Compose    * CouchDB    * dashDB    * Data Warehousing    * DB2    * Elasticsearch    * Gaming    * Geospatial    * Hybrid    * IoT    * Location    * Message Hub    * Migration    * Mobile    * MongoDB    * NoSQL    * Offline    * Open Data    * PostgreSQL    * Redis    * Spark    * SQL      RSS Feed * Report Abuse * Terms of Use * Third Party Notice * IBM PrivacyIBM Send to Email Address Your Name Your Email Address Cancel Post was not sent - check your email addresses! Email check failed, please try again Sorry, your blog cannot share posts by email.'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printout the full article\n",
    "df_content.iloc[10].doc_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Apple's sample app, Food Tracker, taught you iOS. Now, take it further and sync data between devices, through the cloud, with an offline-first design.\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the document description\n",
    "df_content.iloc[10].doc_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Live\n",
       "1    Live\n",
       "2    Live\n",
       "3    Live\n",
       "Name: doc_status, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is document status\n",
    "df_content.iloc[:4].doc_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>doc_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Detect bad readings in real time using Python and Streaming Analytics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>See the forest, see the trees. Here lies the challenge in both performing and presenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Here’s this week’s news in Data Science and Big Data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Learn how distributed DBs solve the problem of scaling persistent storage, but introdu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>This video demonstrates the power of IBM DataScience Experience using a simple New Yor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                                                            doc_description\n",
       "0         0.0                     Detect bad readings in real time using Python and Streaming Analytics.\n",
       "1         1.0  See the forest, see the trees. Here lies the challenge in both performing and presenti...\n",
       "2         2.0                                      Here’s this week’s news in Data Science and Big Data.\n",
       "3         3.0  Learn how distributed DBs solve the problem of scaling persistent storage, but introdu...\n",
       "4         4.0  This video demonstrates the power of IBM DataScience Experience using a simple New Yor..."
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# form a dataframe that has two columns: doc_description and article_id \n",
    "descriptions = df_content[['article_id', 'doc_description']]\n",
    "# check the output\n",
    "descriptions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    This video shows you how to add a data asset to an existing project and then load that...\n",
       "101    Projects can be great for mastering data science, but you have to choose your projects...\n",
       "102    Ever had to make a decision when you didn’t have the time, means or patience to look u...\n",
       "103    by Sean LoppAt RStudio, we work with many companies interested in scaling R. They typi...\n",
       "104    Our fortieth release of a weekly round up of interesting Data Science and Big Data new...\n",
       "105    A summary of Progressive Web Apps and recommendations on refactoring code to use offli...\n",
       "106    Find out why redundant visualizations can turn detail into too much of a good thing, o...\n",
       "107                                         Machine learning is often the enhancer of a product.\n",
       "108    Create a notebook using IBM Data Science Experience using PixieDust to explore and vis...\n",
       "109                          A weekly newsletter about the latest developments in Deep Learning.\n",
       "Name: doc_description, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a closer look at some of these descriptions\n",
    "descriptions.doc_description[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id         0\n",
       "doc_description    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find how many descriptions are missing\n",
    "descriptions.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id         0\n",
       "doc_description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill in 'none' for the missing descriptions\n",
    "descriptions = descriptions.fillna('none')\n",
    "\n",
    "# check the output\n",
    "descriptions.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process the Text and Create TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Contains the pre-processing steps for a document:\n",
    "        - tokenize\n",
    "        - lemmatize\n",
    "        - lowercasing\n",
    "        - removes stopwords in English language\n",
    "        \n",
    "    INPUT (string) - raw message\n",
    "    OUTPUT (list)  - clean tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove punctuation and unusual characters \n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text).strip()\n",
    "    \n",
    "    # split into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # lemmatize - reduce words to their root form\n",
    "    words = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
    "    \n",
    "    # case normalize and remove leading & trailing empty spaces\n",
    "    words = [w.lower().strip() for w in words]\n",
    "    \n",
    "    # remove stopwords, keep not and can\n",
    "    clean_words = [w for w in words if w not in stopwords.words('english') \n",
    "                   or w in ['not', 'can']]\n",
    "    \n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the TF-IDF transformer\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize)\n",
    "\n",
    "# construct the TF-IDF matrix \n",
    "tfidf_matrix = tfidf.fit_transform(descriptions['doc_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1051, 3647)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output the shape of the tfidf matrix\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the cosine similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1051, 1051)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "# check the output\n",
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the recommender function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_info(article_id, df_content=df_content):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_id - (float, integer)\n",
    "    df_content - (pandas dataframe) defined at the top of notebook, \n",
    "                  contains title, full text and article description\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_name - (string) the article name associated with the provided article id\n",
    "    article_description - (string) a brief description for the article\n",
    "    '''\n",
    "    \n",
    "    article_name = df_content[df_content['article_id'] == article_id]['doc_full_name'].unique()[0]\n",
    "    article_description = df_content[df_content['article_id'] == article_id]['doc_description'].unique()[0]\n",
    "    return article_name, article_description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The title of the article with id =56 is: Introducing the Simple Autocomplete Service.\n",
      " \n",
      "A brief description  of the article with id =56:\n",
      " Easily add autocomplete to your web form fields. Simply upload your data set using this cloud service then use its fast and efficient autocomplete API.\n"
     ]
    }
   ],
   "source": [
    "# print a sample output\n",
    "\n",
    "print('The title of the article with id =56 is: {}.'.format(get_article_info(56, df_content)[0]))\n",
    "print(\" \")\n",
    "print('A brief description  of the article with id =56:\\n {}'.format(get_article_info(56, df_content)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in the article id as input and gives n recommendations\n",
    "def content_recommender(article_id, n, cosine_sim=cosine_sim, df_content=df_content):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_id - (float, integer)\n",
    "    n - (integer) how many recommendations should be returned\n",
    "    cosine_sim  - (np.ndarray) matrix of cosine similarities\n",
    "    df_content - (pandas dataframe) defined at the top of notebook, \n",
    "                  contains title, full text and article description\n",
    "    \n",
    "    OUTPUT:\n",
    "    df_recs  - (pd.DataFrame) dataframe of the n recommended articles, sorted by similarity\n",
    "    '''\n",
    "    \n",
    "    # obtain the article name and article description that match the article id\n",
    "    article_name, article_description = get_article_info(article_id, df_content)\n",
    "    \n",
    "    # get the pairwise similarity scores of all articles with the given article\n",
    "    # convert into a list of tuples (position in the matrix, similarity score)\n",
    "    sim_scores = list(enumerate(cosine_sim[article_id]))\n",
    "    \n",
    "    # sort the articles based on the cosine similarity scores\n",
    "    sim_scores_sorted = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # get the scores of the n most similar articles, ignore the first entry\n",
    "    sim_scores_n = sim_scores_sorted[1:n+1]\n",
    "    \n",
    "    # get the similar article ids\n",
    "    sim_article_ids = [i[0] for i in sim_scores_n]\n",
    "    \n",
    "    # create a dataframe of the similar articles\n",
    "    df_recs = df_content['doc_full_name'].iloc[sim_article_ids]\n",
    "    \n",
    "    # return the top n most similar articles\n",
    "    return df_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Using apply, sapply, lapply in R',\n",
       " 'This is an introductory post about using apply, sapply and lapply, best suited for people relatively new to R or unfamiliar with these functions.')"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get information for article id 224\n",
    "get_article_info(224, df_content=df_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "889    Perform market basket analysis using dashDB and R\n",
       "693                  Connecting R and Compose PostgreSQL\n",
       "353              sparklyr — R interface for Apache Spark\n",
       "893       Connecting PHP to Compose for MySQL on Bluemix\n",
       "623     htmlwidgets: JavaScript data visualization for R\n",
       "Name: doc_full_name, dtype: object"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make recommendations for article id 224\n",
    "content_recommender(224, 5, cosine_sim, df_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Working interactively with RStudio and notebooks in DSX',\n",
       " 'It is often useful to use RStudio for one piece of your analysis and notebooks (whether in R, or in another language) for other parts of your analysis. This article will step you through the process…')"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get information for article id 20\n",
    "get_article_info(20, df_content=df_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541    Sentiment Analysis of Reddit AMAs using dashDB and R\n",
       "325                                     Map Your Cloud Data\n",
       "33                Using Brunel in IPython/Jupyter Notebooks\n",
       "564                                RStudio IDE  Cheat Sheet\n",
       "351                                   Do I need to learn R?\n",
       "696        Predict temperatures using dashDB, Python, and R\n",
       "384           An interview with Pythonista Katharine Jarmul\n",
       "509                               Data science in the cloud\n",
       "430                         Why Relational Databases and R?\n",
       "103                     How to Scale Your Analytics Using R\n",
       "Name: doc_full_name, dtype: object"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make recommendations for article 20\n",
    "rec_article20 = content_recommender(20, 10, cosine_sim, df_content)\n",
    "rec_article20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[541, 325, 33, 564, 351, 696, 384, 509, 430, 103]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the article ids for the recommended articles\n",
    "list(rec_article20.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_content_recs(user_id, m=10, df=df, df_content=df_content):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user by article id\n",
    "    rec_names - (list) a list of recommendations for the user by article title\n",
    "    \n",
    "    Description:\n",
    "    Loops through the articles based on closeness to the articles seen by the user.\n",
    "    For each article seen by the user - finds n most similar articles based on content recommendations\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    * Choose the articles that have the most total article interactions \n",
    "    before choosing those with fewer article interactions.\n",
    "   \n",
    "    '''\n",
    "    # list of recommended articles by id, and by title\n",
    "    recommendations = []\n",
    "    \n",
    "    # articles_seen by user \n",
    "    articles_seen = get_user_articles(user_id, user_item)[0]\n",
    "    \n",
    "    # rewrite the recommended article ids as int\n",
    "    articles_ids_seen = [int(x[:-2]) for x in articles_seen]\n",
    "    \n",
    "    # remove all the articles that are not in df_content\n",
    "    articles_available = list(np.intersect1d(np.array(articles_ids_seen), df_content['article_id'],  \n",
    "                                 assume_unique=False,\n",
    "                                 return_indices=False))\n",
    "    articles_available = [int(x) for x in articles_available]\n",
    "\n",
    "    \n",
    "    for index in articles_available:\n",
    "        \n",
    "        # get the n most similar articles \n",
    "        n = 6\n",
    "        similar_articles = content_recommender(index,\n",
    "                                           n, \n",
    "                                           cosine_sim=cosine_sim, \n",
    "                                           df_content=df_content).index.values\n",
    "        \n",
    "        # remove the articles in articles_seen\n",
    "        articles_to_rec = np.setdiff1d(similar_articles, articles_seen)\n",
    "        \n",
    "        # remove the articles already added to the recs list\n",
    "        articles_to_add = np.setdiff1d(articles_to_rec, recommendations)\n",
    "        \n",
    "        # rewrite the recommended article ids as float \n",
    "        articles_ids = [float(x) for x in articles_to_add]\n",
    "        \n",
    "        # sort the articles by popularity, i.e. number of views\n",
    "        #df_red = df[df['article_id'].isin(articles_to_add)]\n",
    "        #sorted_articles = df_red.groupby('article_id').count()['title'].sort_values(ascending=False).index.to_list()\n",
    "       \n",
    "        # add the sorted article ids\n",
    "        recommendations.extend(articles_ids)\n",
    "        \n",
    "        # break when we have enough articles to recommend\n",
    "        if len(recs_ids) >= m:\n",
    "            break\n",
    "    \n",
    "    # retain the first m recommendations\n",
    "    recs = recommendations[:m]\n",
    "    \n",
    "    # get the articles names and descriptions \n",
    "    articles_info = [get_article_info(index, df_content=df_content)[0] for index in recs]\n",
    "    \n",
    "    return recs, articles_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Self-service data preparation with IBM Data Refinery',\n",
       " 'Use the Cloudant-Spark connector in Python notebook']"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# articles seen by user 20\n",
    "articles_seen = get_user_articles(20, user_item)[0]\n",
    "articles_ids_seen = [int(x[:-2]) for x in articles_seen]\n",
    "articles_info = [get_article_info(index, \n",
    "                                  df_content=df_content)[0] for index in articles_ids_seen[:2]]\n",
    "articles_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([115.0, 518.0, 558.0, 742.0, 769.0, 980.0, 161.0, 561.0, 596.0, 812.0],\n",
       " ['Finding the user in data science',\n",
       "  'Cloud Data Warehouse Made Easy',\n",
       "  'Mongo Metrics: Calculating the Mean',\n",
       "  'Deploying a Full Stack Node.js Application to IBM Bluemix',\n",
       "  'Powering social feeds and timelines with Elasticsearch',\n",
       "  'logshare',\n",
       "  'Use the Machine Learning Library in Spark',\n",
       "  'Set Up Pre Authenticated cURL',\n",
       "  'Integration Testing Against Real Databases',\n",
       "  'Machine Learning Exercises In Python, Part 1'])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make recommendations for user 20\n",
    "make_content_recs(20, m=10, df=df, df_content=df_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time Series Prediction Using Recurrent Neural Networks (LSTMs)',\n",
       " 'DSX: Hybrid Mode',\n",
       " 'Web Picks - DataMiningApps',\n",
       " '10 Data Science Podcasts You Need To be Listening To Right Now']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# articles seen by user 178\n",
    "articles_seen = get_user_articles(178, user_item)[0]\n",
    "articles_ids_seen = [int(x[:-2]) for x in articles_seen]\n",
    "articles_info = [get_article_info(index, \n",
    "                                  df_content=df_content)[0] for index in articles_ids_seen]\n",
    "articles_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([142.0, 466.0, 642.0, 788.0, 890.0, 942.0, 385.0, 594.0, 627.0, 656.0],\n",
       " ['Neural networks for beginners: popular types and applications',\n",
       "  \"Compose's Data Browser comes to Elasticsearch\",\n",
       "  'Persisting Data for a Smarter Chatbot',\n",
       "  'Quick Guide to Build a Recommendation Engine in Python',\n",
       "  'Connecting PHP to Compose for MySQL on Bluemix',\n",
       "  'Interview with Sean Li, New Apache Spark™ Committer',\n",
       "  'Load geospatial data into dashDB to analyze in Esri ArcGIS',\n",
       "  'NY Motor Vehicle Accident Analysis',\n",
       "  'Importing Redis data into Compose Redis',\n",
       "  'Deep Learning Achievements Over the Past Year '])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make some recommendations for user 178\n",
    "make_content_recs(178, m=10, df=df, df_content=df_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Now that you have put together your content-based recommendation system, use the cell below to write a summary explaining how your content based recommender works.  Do you see any possible improvements that could be made to your function?  Is there anything novel about your content based recommender?\n",
    "\n",
    "### This part is NOT REQUIRED to pass this project.  However, you may choose to take this on as an extra way to show off your skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write an explanation of your content based recommendation system here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use your content-recommendation system to make recommendations for the below scenarios based on the comments.  Again no tests are provided here, because there isn't one right answer that could be used to find these content based recommendations.\n",
    "\n",
    "### This part is NOT REQUIRED to pass this project.  However, you may choose to take this on as an extra way to show off your skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make recommendations for a brand new user\n",
    "\n",
    "\n",
    "# make a recommendations for a user who only has interacted with article id '1427.0'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Matrix-Fact\">Part V: Matrix Factorization</a>\n",
    "\n",
    "In this part of the notebook, you will build use matrix factorization to make article recommendations to the users on the IBM Watson Studio platform.\n",
    "\n",
    "`1.` You should have already created a **user_item** matrix above in **question 1** of **Part III** above.  This first question here will just require that you run the cells to get things set up for the rest of **Part V** of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the matrix here\n",
    "user_item_matrix = pd.read_pickle('user_item_matrix.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# quick look at the matrix\n",
    "user_item_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` In this situation, you can use Singular Value Decomposition from [numpy](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.svd.html) on the user-item matrix.  Use the cell to perform SVD, and explain why this is different than in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform SVD on the User-Item Matrix Here\n",
    "\n",
    "u, s, vt = # use the built in to get the three matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Provide your response here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Now for the tricky part, how do we choose the number of latent features to use?  Running the below cell, you can see that as the number of latent features increases, we obtain a lower error rate on making predictions for the 1 and 0 values in the user-item matrix.  Run the cell below to get an idea of how the accuracy improves as we increase the number of latent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_latent_feats = np.arange(10,700+10,20)\n",
    "sum_errs = []\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_new, u_new, vt_new = np.diag(s[:k]), u[:, :k], vt[:k, :]\n",
    "    \n",
    "    # take dot product\n",
    "    user_item_est = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(user_item_matrix, user_item_est)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs.append(err)\n",
    "    \n",
    "    \n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs)/df.shape[0]);\n",
    "plt.xlabel('Number of Latent Features');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.title('Accuracy vs. Number of Latent Features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` From the above, we can't really be sure how many features to use, because simply having a better way to predict the 1's and 0's of the matrix doesn't exactly give us an indication of if we are able to make good recommendations.  Instead, we might split our dataset into a training and test set of data, as shown in the cell below.  \n",
    "\n",
    "Use the code from question 3 to understand the impact on accuracy of the training and test sets of data with different numbers of latent features. Using the split below: \n",
    "\n",
    "* How many users can we make predictions for in the test set?  \n",
    "* How many users are we not able to make predictions for because of the cold start problem?\n",
    "* How many articles can we make predictions for in the test set?  \n",
    "* How many articles are we not able to make predictions for because of the cold start problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df.head(40000)\n",
    "df_test = df.tail(5993)\n",
    "\n",
    "def create_test_and_train_user_item(df_train, df_test):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df_train - training dataframe\n",
    "    df_test - test dataframe\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item_train - a user-item matrix of the training dataframe \n",
    "                      (unique users for each row and unique articles for each column)\n",
    "    user_item_test - a user-item matrix of the testing dataframe \n",
    "                    (unique users for each row and unique articles for each column)\n",
    "    test_idx - all of the test user ids\n",
    "    test_arts - all of the test article ids\n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    \n",
    "    return user_item_train, user_item_test, test_idx, test_arts\n",
    "\n",
    "user_item_train, user_item_test, test_idx, test_arts = create_test_and_train_user_item(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace the values in the dictionary below\n",
    "a = 662 \n",
    "b = 574 \n",
    "c = 20 \n",
    "d = 0 \n",
    "\n",
    "\n",
    "sol_4_dict = {\n",
    "    'How many users can we make predictions for in the test set?': # letter here, \n",
    "    'How many users in the test set are we not able to make predictions for because of the cold start problem?': # letter here, \n",
    "    'How many articles can we make predictions for in the test set?': # letter here,\n",
    "    'How many articles in the test set are we not able to make predictions for because of the cold start problem?': # letter here\n",
    "}\n",
    "\n",
    "t.sol_4_test(sol_4_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` Now use the **user_item_train** dataset from above to find U, S, and V transpose using SVD. Then find the subset of rows in the **user_item_test** dataset that you can predict using this matrix decomposition with different numbers of latent features to see how many features makes sense to keep based on the accuracy on the test data. This will require combining what was done in questions `2` - `4`.\n",
    "\n",
    "Use the cells below to explore how well SVD works towards making predictions for recommendations on the test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit SVD on the user_item_train matrix\n",
    "u_train, s_train, vt_train = # fit svd similar to above then use the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use these cells to see how well you can use the training \n",
    "# decomposition to predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`6.` Use the cell below to comment on the results you found in the previous question. Given the circumstances of your results, discuss what you might do to determine if the recommendations you make with any of the above recommendation systems are an improvement to how users currently find articles? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='conclusions'></a>\n",
    "### Extras\n",
    "Using your workbook, you could now save your recommendations for each user, develop a class to make new predictions and update your results, and make a flask app to deploy your results.  These tasks are beyond what is required for this project.  However, from what you learned in the lessons, you certainly capable of taking these tasks on to improve upon your work here!\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "> Congratulations!  You have reached the end of the Recommendations with IBM project! \n",
    "\n",
    "> **Tip**: Once you are satisfied with your work here, check over your report to make sure that it is satisfies all the areas of the [rubric](https://review.udacity.com/#!/rubrics/2322/view). You should also probably remove all of the \"Tips\" like this one so that the presentation is as polished as possible.\n",
    "\n",
    "\n",
    "## Directions to Submit\n",
    "\n",
    "> Before you submit your project, you need to create a .html or .pdf version of this notebook in the workspace here. To do that, run the code cell below. If it worked correctly, you should get a return code of 0, and you should see the generated .html file in the workspace directory (click on the orange Jupyter icon in the upper left).\n",
    "\n",
    "> Alternatively, you can download this report as .html via the **File** > **Download as** submenu, and then manually upload it into the workspace directory by clicking on the orange Jupyter icon in the upper left, then using the Upload button.\n",
    "\n",
    "> Once you've done this, you can submit your project by clicking on the \"Submit Project\" button in the lower right here. This will create and submit a zip file with this .ipynb doc and the .html or .pdf version you created. Congratulations! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Recommendations_with_IBM.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
