{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations with IBM\n",
    "\n",
    "Several recommendation methods are investigated on real data from the IBM Watson Studio platform. \n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "I. [Exploratory Data Analysis](#Exploratory-Data-Analysis)<br>\n",
    "II. [Rank Based Recommendations](#Rank)<br>\n",
    "III. [User-User Based Collaborative Filtering](#User-User)<br>\n",
    "IV. [Content Based Recommendations](#Content-Recs)<br>\n",
    "V. [Matrix Factorization](#Matrix-Fact)<br>\n",
    "VI. [Extras & Concluding](#conclusions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries and packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import test modules\n",
    "import project_tests as t\n",
    "\n",
    "# Packages and libraries for content based recs\n",
    "\n",
    "import re\n",
    "\n",
    "# nlp packages\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# data processing packages\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# import linear kernel to compute the dot product\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 2 decimal places in output display\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "# Don't wrap dataframe across additional lines\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "\n",
    "# Set the maximum widths of columns\n",
    "pd.set_option(\"display.max_colwidth\", 90)\n",
    "\n",
    "# Set max rows displayed in output to 20\n",
    "pd.set_option(\"display.max_rows\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv('data/user-item-interactions.csv')\n",
    "df_content = pd.read_csv('data/articles_community.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier data analysis and experimentation</td>\n",
       "      <td>ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>b96a4f2e92d8572034b1e9b28f9ac673765cd074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>06485706b34a5c9bf2a0ecdac41daf7e7654ceb7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>f01220c46fc92c6e6b161b1849de11faacd7ccb2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                                                             title                                     email\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier data analysis and experimentation  ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7\n",
       "1      1314.0                                      healthcare python streaming application demo  083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b\n",
       "2      1429.0                                        use deep learning for image classification  b96a4f2e92d8572034b1e9b28f9ac673765cd074\n",
       "3      1338.0                                         ml optimization using cognitive assistant  06485706b34a5c9bf2a0ecdac41daf7e7654ceb7\n",
       "4      1276.0                                         deploy your python model as a restful api  f01220c46fc92c6e6b161b1849de11faacd7ccb2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show df to get an idea of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VID...</td>\n",
       "      <td>Detect bad readings in real time using Python and Streaming Analytics.</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streaming Analytics</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n * kaggle.com\\r\\n\\r\\nCommunicating data s...</td>\n",
       "      <td>See the forest, see the trees. Here lies the challenge in both performing and presenti...</td>\n",
       "      <td>Communicating data science: A guide to presenting your work</td>\n",
       "      <td>Live</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Paths\\r\\n * Courses * Our Courses\\r\\n    * ...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Big Data.</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCALE - BOOST THE PERFORMANCE OF YOUR\\r\\nDI...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of scaling persistent storage, but introdu...</td>\n",
       "      <td>DataLayer Conference: Boost the performance of your distributed database</td>\n",
       "      <td>Live</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VID...</td>\n",
       "      <td>This video demonstrates the power of IBM DataScience Experience using a simple New Yor...</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    doc_body                                                                            doc_description                                                             doc_full_name doc_status  article_id\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VID...                     Detect bad readings in real time using Python and Streaming Analytics.                Detect Malfunctioning IoT Sensors with Streaming Analytics       Live           0\n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n * kaggle.com\\r\\n\\r\\nCommunicating data s...  See the forest, see the trees. Here lies the challenge in both performing and presenti...               Communicating data science: A guide to presenting your work       Live           1\n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Paths\\r\\n * Courses * Our Courses\\r\\n    * ...                                      Here’s this week’s news in Data Science and Big Data.                                This Week in Data Science (April 18, 2017)       Live           2\n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCALE - BOOST THE PERFORMANCE OF YOUR\\r\\nDI...  Learn how distributed DBs solve the problem of scaling persistent storage, but introdu...  DataLayer Conference: Boost the performance of your distributed database       Live           3\n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VID...  This video demonstrates the power of IBM DataScience Experience using a simple New Yor...                             Analyze NY Restaurant data using Spark in DSX       Live           4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show df_content to get an idea of the data\n",
    "df_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Exploratory-Data-Analysis\">Part I : Exploratory Data Analysis</a>\n",
    "\n",
    "First we provide some insight into the descriptive statistics of the data.\n",
    "\n",
    "`1.` _What is the distribution of how many articles a user interacts with in the dataset?  Visual and descriptive statistics to assist with giving a look at the number of times each user interacts with an article._  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique user emails is 5148.\n"
     ]
    }
   ],
   "source": [
    "# The number of unique emails\n",
    "print(\"The number of unique user emails is {}.\".format(df.email.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique articles is 1051.\n"
     ]
    }
   ],
   "source": [
    "# The number of unique articles \n",
    "print(\"The number of unique articles is {}.\".format(df_content.article_id.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000b6387a0366322d7fbfc6434af145adf7fed1</td>\n",
       "      <td>[1314.0, 732.0, 173.0, 1354.0, 43.0, 1232.0, 1162.0, 124.0, 1337.0, 349.0, 43.0, 288.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001055fc0bb67f71e8fa17002342b256a30254cd</td>\n",
       "      <td>[124.0, 1386.0, 254.0, 390.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00148e4911c7e04eeff8def7bbbdaf1c59c2c621</td>\n",
       "      <td>[1386.0, 932.0, 258.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001a852ecbd6cc12ab77a785efa137b2646505fe</td>\n",
       "      <td>[349.0, 957.0, 1364.0, 593.0, 1364.0, 232.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001fc95b90da5c3cb12c501d201a915e4f093290</td>\n",
       "      <td>[1364.0, 379.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      email                                                                                 article_id\n",
       "0  0000b6387a0366322d7fbfc6434af145adf7fed1  [1314.0, 732.0, 173.0, 1354.0, 43.0, 1232.0, 1162.0, 124.0, 1337.0, 349.0, 43.0, 288.0...\n",
       "1  001055fc0bb67f71e8fa17002342b256a30254cd                                                              [124.0, 1386.0, 254.0, 390.0]\n",
       "2  00148e4911c7e04eeff8def7bbbdaf1c59c2c621                                                                     [1386.0, 932.0, 258.0]\n",
       "3  001a852ecbd6cc12ab77a785efa137b2646505fe                                               [349.0, 957.0, 1364.0, 593.0, 1364.0, 232.0]\n",
       "4  001fc95b90da5c3cb12c501d201a915e4f093290                                                                            [1364.0, 379.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table to keep track of the articles accessed by a user\n",
    "articles_per_user = pd.pivot_table(df,\n",
    "                    values=['article_id'],\n",
    "                    index='email',\n",
    "                    aggfunc={'article_id': list})\n",
    "articles_per_user.reset_index(inplace=True)\n",
    "\n",
    "# Check the outcome\n",
    "articles_per_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>article_id</th>\n",
       "      <th>articles_count</th>\n",
       "      <th>unique_articles_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>2b6c0f514c2f2b04ad3c4583407dccd0810469ee</td>\n",
       "      <td>[362.0, 409.0, 409.0, 302.0, 409.0, 14.0, 29.0, 1293.0, 1429.0, 1293.0, 720.0, 1304.0,...</td>\n",
       "      <td>364</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>77959baaa9895a7e2bdc9297f8b27c1b6f2cb52a</td>\n",
       "      <td>[943.0, 658.0, 109.0, 43.0, 1170.0, 1172.0, 1314.0, 43.0, 1338.0, 1160.0, 1276.0, 33.0...</td>\n",
       "      <td>363</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>2f5c7feae533ce046f2cb16fb3a29fe00528ed66</td>\n",
       "      <td>[173.0, 1165.0, 1427.0, 651.0, 1274.0, 1165.0, 1274.0, 1425.0, 202.0, 1293.0, 1429.0, ...</td>\n",
       "      <td>170</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>a37adec71b667b297ed2440a9ff7dad427c7ac85</td>\n",
       "      <td>[1293.0, 409.0, 20.0, 1165.0, 1430.0, 1175.0, 939.0, 1425.0, 1368.0, 1274.0, 1175.0, 1...</td>\n",
       "      <td>169</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>8510a5010a5d4c89f5b07baac6de80cd12cfaf93</td>\n",
       "      <td>[930.0, 1057.0, 1314.0, 793.0, 1368.0, 1396.0, 1368.0, 1396.0, 793.0, 427.0, 833.0, 13...</td>\n",
       "      <td>160</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1b520f0f65c0aee52d4235f92fb2de58fa966635</td>\n",
       "      <td>[1166.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>7a67e4a2902a20062e1f2a6835b6e099b34b4f6c</td>\n",
       "      <td>[50.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>c4b7e639e91b1d18e5b9c000f0ad3354888fcdde</td>\n",
       "      <td>[115.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>7a7fb282789944665ffc1cddee5ddbdbd7ca9f64</td>\n",
       "      <td>[299.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>9655144418d25a0e074616840447e6e5dbef0069</td>\n",
       "      <td>[57.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5148 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         email                                                                                 article_id  articles_count  unique_articles_count\n",
       "910   2b6c0f514c2f2b04ad3c4583407dccd0810469ee  [362.0, 409.0, 409.0, 302.0, 409.0, 14.0, 29.0, 1293.0, 1429.0, 1293.0, 720.0, 1304.0,...             364                    135\n",
       "2426  77959baaa9895a7e2bdc9297f8b27c1b6f2cb52a  [943.0, 658.0, 109.0, 43.0, 1170.0, 1172.0, 1314.0, 43.0, 1338.0, 1160.0, 1276.0, 33.0...             363                    135\n",
       "985   2f5c7feae533ce046f2cb16fb3a29fe00528ed66  [173.0, 1165.0, 1427.0, 651.0, 1274.0, 1165.0, 1274.0, 1425.0, 202.0, 1293.0, 1429.0, ...             170                     97\n",
       "3312  a37adec71b667b297ed2440a9ff7dad427c7ac85  [1293.0, 409.0, 20.0, 1165.0, 1430.0, 1175.0, 939.0, 1425.0, 1368.0, 1274.0, 1175.0, 1...             169                     97\n",
       "2680  8510a5010a5d4c89f5b07baac6de80cd12cfaf93  [930.0, 1057.0, 1314.0, 793.0, 1368.0, 1396.0, 1368.0, 1396.0, 793.0, 427.0, 833.0, 13...             160                     96\n",
       "...                                        ...                                                                                        ...             ...                    ...\n",
       "565   1b520f0f65c0aee52d4235f92fb2de58fa966635                                                                                   [1166.0]               1                      1\n",
       "2481  7a67e4a2902a20062e1f2a6835b6e099b34b4f6c                                                                                     [50.0]               1                      1\n",
       "4003  c4b7e639e91b1d18e5b9c000f0ad3354888fcdde                                                                                    [115.0]               1                      1\n",
       "2483  7a7fb282789944665ffc1cddee5ddbdbd7ca9f64                                                                                    [299.0]               1                      1\n",
       "3035  9655144418d25a0e074616840447e6e5dbef0069                                                                                     [57.0]               1                      1\n",
       "\n",
       "[5148 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column that records how many articles a user accessed\n",
    "articles_per_user['articles_count'] = [len(x) for x in articles_per_user.article_id]\n",
    "\n",
    "# Create a column that records how many unique articles the user accessed\n",
    "articles_per_user['unique_articles_count'] = [len(set(x)) for x in articles_per_user.article_id]\n",
    "\n",
    "# Check the outcome\n",
    "articles_per_user.sort_values(by='articles_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1416, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many users accessed one article only\n",
    "one_article_users = articles_per_user[articles_per_user['articles_count'] == 1]\n",
    "one_article_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The histogram of the data\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(articles_per_user.articles_count, bins=20)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Articles accessed')\n",
    "plt.title('How many articles are accessed by a user')\n",
    "plt.xlim(1, 370)\n",
    "plt.ylim(1, 1500)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAEWCAYAAACUr7U+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkZUlEQVR4nO3de7xcVX338c+XBMMlkpNAwJgTSYrHCyHeoAheD0YliBJay2MwlCDYlJYi9sEqqW3BS/pgC1VQowZRgqFgRJQoRcHgAa2ECAiEJESiiUkgEK7CAYqE/p4/1jqyM5k5t5mTSfZ836/XvM6etddee601e+Y3a+19ZisiMDMzs3LYpdkVMDMzs8ZxYDczMysRB3YzM7MScWA3MzMrEQd2MzOzEnFgNzMzKxEHdrMKkq6VNKvZ9RgMSV+V9M/9yNcl6cPbo05WnaSQ9PIa6/z62KA5sJeEpHWS3lmRdpKknzerTjuriDgqIhY0ux59qfb6RsSpEfGZZtXJzJrPgd1sJyRpeLPrUI+dvf42eH7th54DewuR9Oo8xfe4pBWSjsnpk3LaLvn51yVtLmy3UNJHa5S5TtI/SLpL0lOSLpa0X57OflLSTySNLuT/jqQHJP1e0k2SJhfWXSLpy5KuydveIumAvO7Lks6v2PcPqtVL0sQ8zTm8kPbHqc2eka6k8yQ9JmmtpKNq5B2W8z0s6beSTiuWXTlTIukcSQsLzw+T9Ivcv3dK6uzl9TlL0m9y21dK+rPCupMk/bekz0t6FPg28FXgcEndkh4v9OFnC9tNl3SHpCdy2dNq7PtkSatyf/xY0v45XXmfm/Nrdpekg2qU8aFcxpO5r/66sK5T0kZJn5D0APBNSbsU2vyIpEWSxtQoe7SkH0p6KNfxh5LaC+vHSPqmpPvz+u/31QeSRuXjdZOk+yR9VtKwvO7lkm7MbX5Y0rf76g9JI/Kxsl7Sg0qnRXYv1OMf8r7ul3Ry9aNgKwdIWpb3c3VP3yi9P06v6J+7JB1bo+9qvueq5K15PEvaTemz4JF8PP9S0n796MvKY/ecfrTd6uDA3iIk7Qr8ALgO2Bc4HbhM0isjYi3wBPD6nP2tQLekV+fnbwNu7KX49wPvAl4BvA+4FvhHYB/SMfaRQt5rgY5ch9uByyrKOh74FDAaWAPMzekLgOP1wpePfYCpwOX964FtvBFYnev4b8DFklQl318B7yX1zSHAX/R3B5LGA9cAnwXGAB8DvitpbI1NfkPq+1GkPlgoaVxFnX9L6rsTgFOBmyNiZES0Vdn/ocClwD8AbaTXcV2VfMeSXq8/B8YCP+OFfn133u4VuYwPAI/UqP9mUl/tBXwI+LykNxTWv4TUD/sDs0nHxbHA24GXAo8BX65R9i7AN/O2LwOeAb5UWP8tYA9gMql/Pt+PPlgAbAFeTnp93w30nNf+DOm9MhpoB77Yj/74XE5/XS5zPPAvuR7TSK//u0jH/1anzWo4ETiZ1DdbgAsL9T6hJ5Ok1+Z9/VeNcvp6z/XXLNKxOQHYm3T8PVOoU62+hK2P3bnY0IoIP0rwIH1YdQOPFx5PAz/P698KPADsUtjmcuCcvPwt4P+SPnxXk4LdqcCkXNYuvex3ZuH5d4GvFJ6fDny/xrZtQACj8vNLgK8X1r8HuKfwfBXwrrz8d8B/1Sh3Yi53eCGtC/hwXj4JWFNYt0fO/5IqeW8ATi3kfXex7Nz+dxbWnwMszMufAL5VUbcfA7P6+ZreAUwv1Hl9xfqTel7fQtolwGfz8teAz9cou9jGa4FTCut2ycfO/sA7gF8Dh9U6Bnqp//eBM/JyJ/AHYLeK13Nq4fk44Lni69ZL2a8DHits97/A6Cr5qvYBsB/wLLB7Ie144Kd5+VJgPtBesV3V/gAEPAUcUEg7HFibl78BnFtY94p8HL28l9enmP/A3H/DgBHAo0BHXnceMK+fr0kbhfdclfW9Hc8nA78AXjPAvtzm2PVjaB8esZfLsRHR1vMA/raw7qXAhoj430La70jf9CGNyDtJo5GbSB8sb8+Pn1VsV+nBwvIzVZ6PhD9Oa5+bp0Of4IWR0z6F/A8Ulp/u2TYrjlROIH0ZGaw/7icins6LI6vkeymwofD8dwPYx/7AcXna8nGl6fK3kALRNiSdmKeMe/IexNZ9s6Hadr2YQJoF6E89Lyjs91FSoBofETeQRsZfBh6UNF/SXjXqf5SkpZIezeW8p6L+D0XE/1Ts93uF/a4CnicFisqy95D0NUm/y8fOTUBbnu6dADwaEY8NoA/2B3YFNhX2/zXSiBLg47kPlimdtjoZoJf+GEv6gnhbobwf5XQY3HFUmX9XYJ+IeBZYBJyQZ7COp8Z7oZ/vuf76FumL6RX5dMK/5ZnAvvqysi02xBzYW8f9wISeqezsZcB9eflG0qi+My//HHgzKbD3Ng0/EB8EppOmIUeRRtaQPkD7YyEwPU89vpo0Iqzmqfx3j0LaSwZS0YJNpODQ42VV9lVrPxtII/a2wmPPiDi3cidK57QvIs1E7J2/mN3N1n1TeSvGvm7NuAE4oI88Pfn+uqKeu0fELwAi4sKIOJg0zf0K0rR2Zf1HkGZrzgP2y/X/rz7qvwE4qmK/u0XEfWzrTOCVwBsjYi/SF1By+RuAMZLaBtAHG0ijzH0K+94rIibnNj8QEX8VES8F/hqYp/yvaTX642HSl9jJhfJGRUTPl8W+jqNqKvM/l/cD6UvuTNLpqKcj4uYaZQz0PVfzeI6I5yLiUxFxIPAm0mmXE+mjL3s2762h1lgO7K3jFtKb9uOSdlW6iOt9wBUAEXEv6YPpBOCmiHiCNPJ+P40L7C8mfQA8Qvrw+NeBbBwRG4FfkkYO342IZ2rke4j0heWEPGI5mf4FuGoWAR+R1K50EeBZFevvAGbkPq08B78QeJ+kI3M9dlO6iKydbe1J+vB7CNKFaKQRe28eBNolvajG+ouBD0maqnSh2nhJr6qS76vAnJ6LqvKFUMfl5T+V9MY8MnsK+B/SqLrSi0hTxA8BW5QuRnx3H/X/KjBXL1yoN1bS9Bp5X0w6Ph9Xuojs7J4VEbGJdDphntJFdrtK6gn8Vfsgb3MdcL6kvfK6AyS9PdfluMLr9BjptXm+Vn/kGa2LSNcV7JvLGC/pyFzGIuAkSQdK2qNY/16cUMj/aeDKiHg+t/lm0umH8+l95mqg77k7qHE8SzpC0pQ8S/IE6YvG8331pW1/DuwtIiL+ABwDHEX61j8PODEi7ilkuxF4JCLWF54L+FWDqnEpaUrxPmAlsHQQZSwAptD3NPxfkUZSj5BGVr8YxL4gfVj/GLiTdOHRVRXr/5n0peEx0gVv/9mzIiI2kEZL/0gKeBtynbZ530XEStKH9M2kgD0F+O8+6nYDsAJ4QNLDlSsjYhn5Ijbg96TXc/8q+b5HuvDrijxdezfpOIF0IdxFuX2/I/XneVXKeJJ0MdyinPeDwOI+6n9BznOdpCdJx8Mba+T9ArA76dhdSprmLvpLUqC5h3QR30dzvXrrgxNJX0hW5jpfyQunSf4UuEVSd67jGZEuMu2tPz5BuuBzae7Hn5BmGYiIa3Mbbsh5buijbyAd45eQThvtxtYXoUJ6P00hfYGsZaDvuZrHM2n0fiUpqK8i9WXPvnvrS9vOFOEZEtt55JHYQmBiH+f9h2r/E4G1wK4RsWV779+sh6QTgdkR8ZZm18V2LB6x204jT3+eQbpyfrsHdbMdRZ6e/1vSlftmW3Fgt52C0v/UP06a3vtCUytj1kT5vP1DpFM2/9lHdmtBnoo3MzMrEY/YzczMSmSH/zH+YXuMiuGj9u074wBMGT+qoeU12lNPPcWee+7Z7Go0jdvv9rdy+8F90Ortv+222x6OiFo/Pd2nHT6wDx+1L+NmfaGhZd567tENLa/Rurq66OzsbHY1msbtd/tbuf3gPmj19ksayC9cbsNT8WZmZiXiwG5mZlYiDuxmZmYl4sBuZmZWIg7sZmZmJeLAbmZmViIO7GZmZiXiwG5mZlYiDuxmZmYl4sBuZmZWIn0GdknfkLRZ0t1V1n1MUkjap5A2R9IaSavz7QV70g+WtDyvu1CSGtcMMzMzg/6N2C8BplUmSpoAvAtYX0g7EJgBTM7bzJM0LK/+CjAb6MiPbco0MzOz+vQZ2CPiJuDRKqs+D3wcKN7QfTpwRUQ8GxFrgTXAoZLGAXtFxM2RbgB/KXBsvZU3MzOzrQ3q7m6SjgHui4g7K2bUxwNLC8835rTn8nJleq3yZ5NG97TtPZYzp2wZTDVr6urqamh5jdbd3b3D13Eouf1ufyu3H9wHrd7+eg04sEvaA/gk8O5qq6ukRS/pVUXEfGA+wIhxHXH+8sbeXXbdzM6GltdorX7LQrff7W/l9oP7oNXbX6/BRMwDgElAz2i9Hbhd0qGkkfiEQt524P6c3l4l3czMzBpowP/uFhHLI2LfiJgYERNJQfsNEfEAsBiYIWmEpEmki+SWRcQm4ElJh+Wr4U8Erm5cM8zMzAz69+9ulwM3A6+UtFHSKbXyRsQKYBGwEvgRcFpEPJ9X/w3wddIFdb8Brq2z7mZmZlahz6n4iDi+j/UTK57PBeZWyXcrcNAA62dmZmYD4F+eMzMzKxEHdjMzsxJxYDczMysRB3YzM7MScWA3MzMrEQd2MzOzEnFgNzMzKxEHdjMzsxJxYDczMysRB3YzM7MScWA3MzMrEQd2MzOzEnFgNzMzKxEHdjMzsxJxYDczMysRB3YzM7MScWA3MzMrEQd2MzOzEnFgNzMzKxEHdjMzsxLpM7BL+oakzZLuLqT9u6R7JN0l6XuS2grr5khaI2m1pCML6QdLWp7XXShJDW+NmZlZi+vPiP0SYFpF2vXAQRHxGuDXwBwASQcCM4DJeZt5koblbb4CzAY68qOyTDMzM6tTn4E9Im4CHq1Iuy4ituSnS4H2vDwduCIino2ItcAa4FBJ44C9IuLmiAjgUuDYBrXBzMzMsuENKONk4Nt5eTwp0PfYmNOey8uV6VVJmk0a3dO291jOnLKlVtZB6erqamh5jdbd3b3D13Eouf1ufyu3H9wHrd7+etUV2CV9EtgCXNaTVCVb9JJeVUTMB+YDjBjXEecvb8T3jxesm9nZ0PIarauri87OzmZXo2ncfre/ldsP7oNWb3+9Bh0xJc0C3gtMzdPrkEbiEwrZ2oH7c3p7lXQzMzNroEH9u5ukacAngGMi4unCqsXADEkjJE0iXSS3LCI2AU9KOixfDX8icHWddTczM7MKfY7YJV0OdAL7SNoInE26Cn4EcH3+r7WlEXFqRKyQtAhYSZqiPy0ins9F/Q3pCvvdgWvzw8zMzBqoz8AeEcdXSb64l/xzgblV0m8FDhpQ7czMzGxA/MtzZmZmJeLAbmZmViIO7GZmZiXiwG5mZlYiDuxmZmYl4sBuZmZWIg7sZmZmJeLAbmZmViIO7GZmZiXiwG5mZlYiDuxmZmYl4sBuZmZWIg7sZmZmJeLAbmZmViIO7GZmZiXiwG5mZlYiDuxmZmYl4sBuZmZWIg7sZmZmJeLAbmZmViJ9BnZJ35C0WdLdhbQxkq6XdG/+O7qwbo6kNZJWSzqykH6wpOV53YWS1PjmmJmZtbb+jNgvAaZVpJ0FLImIDmBJfo6kA4EZwOS8zTxJw/I2XwFmAx35UVmmmZmZ1anPwB4RNwGPViRPBxbk5QXAsYX0KyLi2YhYC6wBDpU0DtgrIm6OiAAuLWxjZmZmDTJ8kNvtFxGbACJik6R9c/p4YGkh38ac9lxerkyvStJs0uietr3HcuaULYOsZnVdXV0NLa/Ruru7d/g6DiW33+1v5faD+6DV21+vwQb2WqqdN49e0quKiPnAfIAR4zri/OWNrea6mZ0NLa/Rurq66OzsbHY1msbtd/tbuf3gPmj19tdrsFfFP5in18l/N+f0jcCEQr524P6c3l4l3czMzBposIF9MTArL88Cri6kz5A0QtIk0kVyy/K0/ZOSDstXw59Y2MbMzMwapM85bkmXA53APpI2AmcD5wKLJJ0CrAeOA4iIFZIWASuBLcBpEfF8LupvSFfY7w5cmx9mZmbWQH0G9og4vsaqqTXyzwXmVkm/FThoQLUzMzOzAfEvz5mZmZWIA7uZmVmJOLCbmZmViAO7mZlZiTiwm5mZlYgDu5mZWYk4sJuZmZWIA7uZmVmJOLCbmZmViAO7mZlZiTiwm5mZlYgDu5mZWYk4sJuZmZWIA7uZmVmJOLCbmZmViAO7mZlZiTiwm5mZlYgDu5mZWYk4sJuZmZWIA7uZmVmJ1BXYJf29pBWS7pZ0uaTdJI2RdL2ke/Pf0YX8cyStkbRa0pH1V9/MzMyKBh3YJY0HPgIcEhEHAcOAGcBZwJKI6ACW5OdIOjCvnwxMA+ZJGlZf9c3MzKyo3qn44cDukoYDewD3A9OBBXn9AuDYvDwduCIino2ItcAa4NA6929mZmYFiojBbyydAcwFngGui4iZkh6PiLZCnsciYrSkLwFLI2JhTr8YuDYirqxS7mxgNkDb3mMP/vQFFw26jtVMGT+qoeU1Wnd3NyNHjmx2NZrG7Xf7W7n94D5o9fYfccQRt0XEIYPdfvhgN8znzqcDk4DHge9IOqG3TaqkVf1WERHzgfkAI8Z1xPnLB13NqtbN7GxoeY3W1dVFZ2dns6vRNG6/29/K7Qf3Qau3v171TMW/E1gbEQ9FxHPAVcCbgAcljQPIfzfn/BuBCYXt20lT92ZmZtYg9QT29cBhkvaQJGAqsApYDMzKeWYBV+flxcAMSSMkTQI6gGV17N/MzMwqDHqOOyJukXQlcDuwBfgVafp8JLBI0imk4H9czr9C0iJgZc5/WkQ8X2f9zczMrKCuk9cRcTZwdkXys6TRe7X8c0kX25mZmdkQ8C/PmZmZlYgDu5mZWYk4sJuZmZWIA7uZmVmJOLCbmZmViAO7mZlZiTiwm5mZlYgDu5mZWYk4sJuZmZWIA7uZmVmJOLCbmZmViAO7mZlZiTiwm5mZlYgDu5mZWYk4sJuZmZVIXfdj31lNPOuaISl33blHD0m5ZmZm/eURu5mZWYk4sJuZmZWIA7uZmVmJOLCbmZmVSF2BXVKbpCsl3SNplaTDJY2RdL2ke/Pf0YX8cyStkbRa0pH1V9/MzMyK6h2xXwD8KCJeBbwWWAWcBSyJiA5gSX6OpAOBGcBkYBowT9KwOvdvZmZmBYMO7JL2At4GXAwQEX+IiMeB6cCCnG0BcGxeng5cERHPRsRaYA1w6GD3b2ZmZttSRAxuQ+l1wHxgJWm0fhtwBnBfRLQV8j0WEaMlfQlYGhELc/rFwLURcWWVsmcDswHa9h578KcvuGhQddzepowf1ZByuru7GTlyZEPK2hm5/W5/K7cf3Aet3v4jjjjitog4ZLDb1/MDNcOBNwCnR8Qtki4gT7vXoCppVb9VRMR80pcGRozriPOX7xy/o7NuZmdDyunq6qKzszFl7Yzcfre/ldsP7oNWb3+96jnHvhHYGBG35OdXkgL9g5LGAeS/mwv5JxS2bwfur2P/ZmZmVmHQgT0iHgA2SHplTppKmpZfDMzKabOAq/PyYmCGpBGSJgEdwLLB7t/MzMy2Ve8c9+nAZZJeBPwW+BDpy8IiSacA64HjACJihaRFpOC/BTgtIp6vc/9mZmZWUFdgj4g7gGon+KfWyD8XmFvPPs3MzKw2//KcmZlZiTiwm5mZlYgDu5mZWYk4sJuZmZWIA7uZmVmJOLCbmZmViAO7mZlZiTiwm5mZlYgDu5mZWYk4sJuZmZWIA7uZmVmJOLCbmZmViAO7mZlZiTiwm5mZlYgDu5mZWYk4sJuZmZWIA7uZmVmJOLCbmZmViAO7mZlZiTiwm5mZlUjdgV3SMEm/kvTD/HyMpOsl3Zv/ji7knSNpjaTVko6sd99mZma2tUaM2M8AVhWenwUsiYgOYEl+jqQDgRnAZGAaME/SsAbs38zMzLK6ArukduBo4OuF5OnAgry8ADi2kH5FRDwbEWuBNcCh9ezfzMzMtja8zu2/AHwceHEhbb+I2AQQEZsk7ZvTxwNLC/k25rRtSJoNzAZo23ssZ07ZUmc1t4+urq6GlNPd3d2wsnZGbr/b38rtB/dBq7e/XoMO7JLeC2yOiNskdfZnkyppUS1jRMwH5gOMGNcR5y+v9/vH9rFuZmdDyunq6qKzszFl7Yzcfre/ldsP7oNWb3+96omYbwaOkfQeYDdgL0kLgQcljcuj9XHA5px/IzChsH07cH8d+zczM7MKgz7HHhFzIqI9IiaSLoq7ISJOABYDs3K2WcDVeXkxMEPSCEmTgA5g2aBrbmZmZtsYijnuc4FFkk4B1gPHAUTECkmLgJXAFuC0iHh+CPZvZmbWshoS2COiC+jKy48AU2vkmwvMbcQ+zczMbFv+5TkzM7MScWA3MzMrEQd2MzOzEnFgNzMzKxEHdjMzsxJxYDczMysRB3YzM7MScWA3MzMrEQd2MzOzEnFgNzMzKxEHdjMzsxJxYDczMysRB3YzM7MScWA3MzMrEQd2MzOzEmnI/dgtmXjWNQ0p58wpWzgpl7Xu3KMbUqaZmbUGj9jNzMxKxIHdzMysRBzYzczMSsSB3czMrEQGHdglTZD0U0mrJK2QdEZOHyPpekn35r+jC9vMkbRG0mpJRzaiAWZmZvaCekbsW4AzI+LVwGHAaZIOBM4ClkREB7AkPyevmwFMBqYB8yQNq6fyZmZmtrVBB/aI2BQRt+flJ4FVwHhgOrAgZ1sAHJuXpwNXRMSzEbEWWAMcOtj9m5mZ2bYUEfUXIk0EbgIOAtZHRFth3WMRMVrSl4ClEbEwp18MXBsRV1YpbzYwG6Bt77EHf/qCi+qu485kv93hwWfS8pTxo5pbmSbo7u5m5MiRza5G07j9rd1+cB+0evuPOOKI2yLikMFuX/cP1EgaCXwX+GhEPCGpZtYqaVW/VUTEfGA+wIhxHXH+8tb6HZ0zp2yhp83rZnY2tzJN0NXVRWdnZ7Or0TRuf2u3H9wHrd7+etV1VbykXUlB/bKIuConPyhpXF4/Dtic0zcCEwqbtwP317N/MzMz21o9V8ULuBhYFRH/UVi1GJiVl2cBVxfSZ0gaIWkS0AEsG+z+zczMbFv1zHG/GfhLYLmkO3LaPwLnAosknQKsB44DiIgVkhYBK0lX1J8WEc/XsX8zMzOrMOjAHhE/p/p5c4CpNbaZC8wd7D7NzMysd/7lOTMzsxJxYDczMysRB3YzM7MScWA3MzMrEQd2MzOzEnFgNzMzK5HW+q3WndDEs64ZknLXnXv0kJRrZmbN5RG7mZlZiTiwm5mZlYgDu5mZWYk4sJuZmZWIA7uZmVmJ+Kr4FjUUV9v7Snszs+bziN3MzKxEHNjNzMxKxFPx1jCNmt4/c8oWTiqU5Sl+M7P+84jdzMysRBzYzczMSsSB3czMrEQc2M3MzErEF8/ZDm+o7nC3o/LFg2ZWDwd2sxblHykyKycHdrMdXKvNWOzsGvF6edbG6qGIaHYdeiXpIeB3za7HdrYP8HCzK9FEbr/b38rtB/dBq7f/lRHx4sFuvMOP2CNibLPrsL1JujUiDml2PZrF7Xf7W7n94D5w+3VrPdv7qngzM7MScWA3MzMrEQf2HdP8Zlegydz+1tbq7Qf3gdtfhx3+4jkzMzPrP4/YzczMSsSB3czMrEQc2JtI0gRJP5W0StIKSWfk9DGSrpd0b/47utl1HUqShkn6laQf5uet1v42SVdKuicfC4e3Uh9I+vt8/N8t6XJJu5W5/ZK+IWmzpLsLaTXbK2mOpDWSVks6sjm1bpwa7f/3fPzfJel7ktoK60rVfqjeB4V1H5MUkvYppA2oDxzYm2sLcGZEvBo4DDhN0oHAWcCSiOgAluTnZXYGsKrwvNXafwHwo4h4FfBaUl+0RB9IGg98BDgkIg4ChgEzKHf7LwGmVaRVbW/+PJgBTM7bzJM0bPtVdUhcwrbtvx44KCJeA/wamAOlbT9U7wMkTQDeBawvpA24DxzYmygiNkXE7Xn5SdIH+nhgOrAgZ1sAHNuUCm4HktqBo4GvF5Jbqf17AW8DLgaIiD9ExOO0UB+Qfihrd0nDgT2A+ylx+yPiJuDRiuRa7Z0OXBERz0bEWmANcOj2qOdQqdb+iLguIrbkp0uB9rxcuvZDzWMA4PPAx4HiVe0D7gMH9h2EpInA64FbgP0iYhOk4A/s28SqDbUvkA7k/y2ktVL7/wR4CPhmPh3xdUl70iJ9EBH3AeeRRiibgN9HxHW0SPsLarV3PLChkG9jTiuzk4Fr83LLtF/SMcB9EXFnxaoB94ED+w5A0kjgu8BHI+KJZtdne5H0XmBzRNzW7Lo00XDgDcBXIuL1wFOUa9q5V/lc8nRgEvBSYE9JJzS3VjsUVUkr7f8oS/ok6RTlZT1JVbKVrv2S9gA+CfxLtdVV0nrtAwf2JpO0KymoXxYRV+XkByWNy+vHAZubVb8h9mbgGEnrgCuAd0haSOu0H9K3740RcUt+fiUp0LdKH7wTWBsRD0XEc8BVwJtonfb3qNXejcCEQr520qmK0pE0C3gvMDNe+IGVVmn/AaQvt3fmz8N24HZJL2EQfeDA3kSSRDq3uioi/qOwajEwKy/PAq7e3nXbHiJiTkS0R8RE0sUhN0TECbRI+wEi4gFgg6RX5qSpwEpapw/WA4dJ2iO/H6aSrjVplfb3qNXexcAMSSMkTQI6gGVNqN+QkjQN+ARwTEQ8XVjVEu2PiOURsW9ETMyfhxuBN+TPh4H3QUT40aQH8BbSlMpdwB358R5gb9KVsffmv2OaXdft0BedwA/zcku1H3gdcGs+Dr4PjG6lPgA+BdwD3A18CxhR5vYDl5OuJ3guf4Cf0lt7SVO0vwFWA0c1u/5D1P41pPPIPZ+DXy1r+2v1QcX6dcA+g+0D/6SsmZlZiXgq3szMrEQc2M3MzErEgd3MzKxEHNjNzMxKxIHdzMysRBzYzfogaWLlXZgknSPpY31sd4ikC4e2dv2T2/DBwvM+6yZpXfEOU2VX7XU22xkNb3YFzMoqIm4l/X96U+Wbq0wEPgj8J+w4dTOzxvOI3axOkrokfU7SMkm/lvTWnN6pF+4xv7ek6/KNXr4m6XeS9qkcJeZ7MZ+Tlw+Q9CNJt0n6maRXVdn3oZJ+kcv9Rc8v2Ek6SdJ3JP0AuA44F3irpDuU7n9erNtISd+UtDzfD/v9VfZzQm7fHbn+w/LjEqX7qC+X9PdVtnufpFty/X4iab/e9ilpmqTbJd0paUlO21Pp/tW/zOVMz+mTC3W6S1JHzntN3v5uSR/IeQ+WdGPuyx8Xfr714Jz3ZuC0QR4CZjsUj9jNGmN4RBwq6T3A2aTfQC86G/h5RHxa0tHA7H6UOR84NSLulfRGYB7wjoo89wBvi4gtkt4J/CvQE5gPB14TEY9K6gQ+FhHvhfSlo1DGP5PuqjYlrxtd3IGkVwMfAN4cEc9JmgfMBFYA4yPdRx1JbVXa8HPgsIgISR8m3cnvzGr7lDQWuCi3Z62kMbmMT5J+bvjkvI9lkn4CnApcEBGXSXoR6V7u7wHuj4ijc7mjlO7H8EVgekQ8lIP9XNJdxL4JnB4RN0r696qvgtlOxoHdrG+1fp6xmN5zA5/bSNPeld4G/DlARFwj6bHedqh0x783Ad+R/nhzpxFVso4CFkjqyPXZtbDu+oiods/nSu8k/VY/uX6VdZsKHAz8Mtdld9JNSn4A/ImkLwLXkGYGKrUD384j5BcBa2vtU9L7gJsi3XOaQt3fTbpZUM81DbsBLwNuBj4pqR24Kn8BWg6cJ+lzpJ8o/pmkg4CDgOtz/YcBmySNAtoi4sZc7reAo/rRX2Y7NAd2s749Qvr99qIxvBCkAJ7Nf5+n9vuq2heELWx9Smy3/HcX4PGIeF0fdfsM8NOI+DNJE4Guwrqn+ti2h2rUrbh+QUTM2WaF9FrgSNI09v8hjYKLvgj8R0QszrME5/Syz1r1EPD+iFhdkb5K0i3A0cCPJX04Im6QdDBp5P7/JF0HfA9YERGHV9S9rcb+zHZqPsdu1oeI6CaN8KYC5CniaaRp5v66iTR9jaSjeOGLwoPAvkrn4EeQbltJRDwBrJV0XN5GOYhWGgXcl5dP6mX/TwIvrrHuOuDvep5UTsWTbkryF5L2zevHSNpf6Yr5XSLiu6Sp9Tf0Ub9ZhfRq+7wZeLvSHax6+hngx8DpysNtSa/Pf/8E+G1EXEi6A9ZrJL0UeDoiFgLn5TqtBsZKOjxvt6ukyRHxOPB7SW/J+5lZo3/MdioO7Gb9cyLwT5LuAG4APhURvxnA9p8C3ibpdtLU8nqASPcg/zRwC/BD0jnzHjOBUyTdSTqfPb1Kuf9GGpn+N2mKuZa7gC35QrHKi9w+C4zOF5vdCRxRXBkRK4F/Aq6TdBdwPTAOGA905T65BNhmRE8aoX9H0s+Ah3vbZ0Q8RLr24Kqc9u2c9zOkUwx3KV1o+Jmc/gHg7rz/VwGXAlNI5+DvIJ2b/2xE/AH4C+Bzudw7SKc5AD4EfDlfPPdM7e4z23n47m5mTSBpHXBIRDzcV14zs4HwiN3MzKxEPGI3MzMrEY/YzczMSsSB3czMrEQc2M3MzErEgd3MzKxEHNjNzMxK5P8Dg43fmNImS28AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The histogram of the data\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(articles_per_user.unique_articles_count, bins=20)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Unique articles accessed')\n",
    "plt.title('How many unique articles are accessed by a user')\n",
    "plt.xlim(1, 140)\n",
    "plt.ylim(1, 1500)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles_count</th>\n",
       "      <th>unique_articles_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5148.00</td>\n",
       "      <td>5148.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.93</td>\n",
       "      <td>6.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.80</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>364.00</td>\n",
       "      <td>135.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       articles_count  unique_articles_count\n",
       "count         5148.00                5148.00\n",
       "mean             8.93                   6.54\n",
       "std             16.80                   9.99\n",
       "min              1.00                   1.00\n",
       "25%              1.00                   1.00\n",
       "50%              3.00                   3.00\n",
       "75%              9.00                   7.00\n",
       "max            364.00                 135.00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 numbers descriptive statistics for the number of articles accessed by users\n",
    "articles_per_user.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Boxplot for the unique articles accessed by a user\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.boxplot(articles_per_user.unique_articles_count, vert=False)\n",
    "\n",
    "plt.title('Unique articles counts per user')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1170.0</td>\n",
       "      <td>apache spark lab, part 1: basic concepts</td>\n",
       "      <td>1588af175b283915f597fc4719cbb2c8621c4fc2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1170.0</td>\n",
       "      <td>apache spark lab, part 1: basic concepts</td>\n",
       "      <td>363cb98a087e4a3eb6890fd1af2d418116f85ff8</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>2b6c0f514c2f2b04ad3c4583407dccd0810469ee</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>77959baaa9895a7e2bdc9297f8b27c1b6f2cb52a</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>c8afd6f4620184042cc48ca0eba9a657ac89e90e</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                       title                                     email  counts\n",
       "0      1170.0    apache spark lab, part 1: basic concepts  1588af175b283915f597fc4719cbb2c8621c4fc2      42\n",
       "1      1170.0    apache spark lab, part 1: basic concepts  363cb98a087e4a3eb6890fd1af2d418116f85ff8      41\n",
       "2      1429.0  use deep learning for image classification  2b6c0f514c2f2b04ad3c4583407dccd0810469ee      35\n",
       "3      1429.0  use deep learning for image classification  77959baaa9895a7e2bdc9297f8b27c1b6f2cb52a      35\n",
       "4      1429.0  use deep learning for image classification  c8afd6f4620184042cc48ca0eba9a657ac89e90e      25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe to record the number of times each user interacts with an article\n",
    "article_user = df.value_counts(ascending=False).to_frame('counts').reset_index()\n",
    "article_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33669.00</td>\n",
       "      <td>33669.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>848.38</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>492.26</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>349.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>996.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1320.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1444.00</td>\n",
       "      <td>42.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id    counts\n",
       "count    33669.00  33669.00\n",
       "mean       848.38      1.37\n",
       "std        492.26      1.18\n",
       "min          0.00      1.00\n",
       "25%        349.00      1.00\n",
       "50%        996.00      1.00\n",
       "75%       1320.00      1.00\n",
       "max       1444.00     42.00"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 Values descriptive statistics for how many times users interact with one article\n",
    "article_user.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% of individuals interact with 3.0 articles or fewer.\n",
      "The maximum number of user-article interactions by any user is 364.\n"
     ]
    }
   ],
   "source": [
    "# Fill in the median and maximum number of user_article interactions below\n",
    "\n",
    "median_val = df.groupby('email').count()['article_id'].median()\n",
    "print('50% of individuals interact with {} articles or fewer.'.format(median_val))\n",
    "max_views_by_user = df.groupby('email').count()['article_id'].max()\n",
    "print('The maximum number of user-article interactions by any user is {}.'.format(max_views_by_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` _Explore and remove duplicate articles from the `df_content` dataframe._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and explore duplicate articles\n",
    "duplicate_articles = df_content[df_content['article_id'].duplicated()]\n",
    "duplicate_articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Follow Sign in / Sign up Home About Insight Data Science Data Engineering Health Data ...</td>\n",
       "      <td>During the seven-week Insight Data Engineering Fellows Program recent grads and experi...</td>\n",
       "      <td>Graph-based machine learning</td>\n",
       "      <td>Live</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * Home\\r\\n * Data Science Experience\\r\\n * ...</td>\n",
       "      <td>One of the earliest documented catalogs was compiled at the great library of Alexandri...</td>\n",
       "      <td>How smart catalogs can turn the big data flood into an ocean of opportunity</td>\n",
       "      <td>Live</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>Homepage Follow Sign in Get started Homepage * Home\\r\\n * Data Science Experience\\r\\n ...</td>\n",
       "      <td>Today’s world of data science leverages data from various sources. Commonly, these sou...</td>\n",
       "      <td>Using Apache Spark as a parallel processing framework for accessing REST based data se...</td>\n",
       "      <td>Live</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>This video shows you how to construct queries to access the primary index through the ...</td>\n",
       "      <td>This video shows you how to construct queries to access the primary index through the API</td>\n",
       "      <td>Use the Primary Index</td>\n",
       "      <td>Live</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Homepage Follow Sign in Get started * Home\\r\\n * Data Science Experience\\r\\n * Data Ca...</td>\n",
       "      <td>If you are like most data scientists, you are probably spending a lot of time to clean...</td>\n",
       "      <td>Self-service data preparation with IBM Data Refinery</td>\n",
       "      <td>Live</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      doc_body                                                                            doc_description                                                                              doc_full_name doc_status  article_id\n",
       "365  Follow Sign in / Sign up Home About Insight Data Science Data Engineering Health Data ...  During the seven-week Insight Data Engineering Fellows Program recent grads and experi...                                                               Graph-based machine learning       Live          50\n",
       "692  Homepage Follow Sign in / Sign up Homepage * Home\\r\\n * Data Science Experience\\r\\n * ...  One of the earliest documented catalogs was compiled at the great library of Alexandri...                How smart catalogs can turn the big data flood into an ocean of opportunity       Live         221\n",
       "761  Homepage Follow Sign in Get started Homepage * Home\\r\\n * Data Science Experience\\r\\n ...  Today’s world of data science leverages data from various sources. Commonly, these sou...  Using Apache Spark as a parallel processing framework for accessing REST based data se...       Live         398\n",
       "970  This video shows you how to construct queries to access the primary index through the ...  This video shows you how to construct queries to access the primary index through the API                                                                      Use the Primary Index       Live         577\n",
       "971  Homepage Follow Sign in Get started * Home\\r\\n * Data Science Experience\\r\\n * Data Ca...  If you are like most data scientists, you are probably spending a lot of time to clean...                                       Self-service data preparation with IBM Data Refinery       Live         232"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [doc_body, doc_description, doc_full_name, doc_status, article_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove any rows that have the same article_id - only keep the first\n",
    "df_content.drop_duplicates(subset=['article_id'], keep='first', inplace=True)\n",
    "\n",
    "# Check the outcome\n",
    "df_content[df_content['article_id'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` _In the cells below we find:_\n",
    "\n",
    "**a.** _The number of unique articles that have an interaction with a user.  \n",
    "**b.** The number of unique articles in the dataset (whether they have any interactions or not).<br>\n",
    "**c.** The number of unique users in the dataset. (excluding null values) <br>\n",
    "**d.** The number of user-article interactions in the dataset._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25131</th>\n",
       "      <td>1016.0</td>\n",
       "      <td>why you should master r (even if it might eventually become obsolete)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29758</th>\n",
       "      <td>1393.0</td>\n",
       "      <td>the nurse assignment problem</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29759</th>\n",
       "      <td>20.0</td>\n",
       "      <td>working interactively with rstudio and notebooks in dsx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29760</th>\n",
       "      <td>1174.0</td>\n",
       "      <td>breast cancer wisconsin (diagnostic) data set</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29761</th>\n",
       "      <td>62.0</td>\n",
       "      <td>data visualization: the importance of excluding unnecessary details</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35264</th>\n",
       "      <td>224.0</td>\n",
       "      <td>using apply, sapply, lapply in r</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35276</th>\n",
       "      <td>961.0</td>\n",
       "      <td>beyond parallelize and collect</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35277</th>\n",
       "      <td>268.0</td>\n",
       "      <td>sector correlations shiny app</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35278</th>\n",
       "      <td>268.0</td>\n",
       "      <td>sector correlations shiny app</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35279</th>\n",
       "      <td>268.0</td>\n",
       "      <td>sector correlations shiny app</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35280</th>\n",
       "      <td>268.0</td>\n",
       "      <td>sector correlations shiny app</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35281</th>\n",
       "      <td>415.0</td>\n",
       "      <td>using machine learning to predict value of homes on airbnb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35282</th>\n",
       "      <td>846.0</td>\n",
       "      <td>pearson correlation aggregation on sparksql</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35283</th>\n",
       "      <td>268.0</td>\n",
       "      <td>sector correlations shiny app</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35284</th>\n",
       "      <td>162.0</td>\n",
       "      <td>an introduction to stock market data analysis with r (part 1)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42749</th>\n",
       "      <td>647.0</td>\n",
       "      <td>getting started with apache mahout</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42750</th>\n",
       "      <td>965.0</td>\n",
       "      <td>data visualization playbook: revisiting the basics</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id                                                                  title email\n",
       "25131      1016.0  why you should master r (even if it might eventually become obsolete)   NaN\n",
       "29758      1393.0                                           the nurse assignment problem   NaN\n",
       "29759        20.0                working interactively with rstudio and notebooks in dsx   NaN\n",
       "29760      1174.0                          breast cancer wisconsin (diagnostic) data set   NaN\n",
       "29761        62.0    data visualization: the importance of excluding unnecessary details   NaN\n",
       "35264       224.0                                       using apply, sapply, lapply in r   NaN\n",
       "35276       961.0                                         beyond parallelize and collect   NaN\n",
       "35277       268.0                                          sector correlations shiny app   NaN\n",
       "35278       268.0                                          sector correlations shiny app   NaN\n",
       "35279       268.0                                          sector correlations shiny app   NaN\n",
       "35280       268.0                                          sector correlations shiny app   NaN\n",
       "35281       415.0             using machine learning to predict value of homes on airbnb   NaN\n",
       "35282       846.0                            pearson correlation aggregation on sparksql   NaN\n",
       "35283       268.0                                          sector correlations shiny app   NaN\n",
       "35284       162.0          an introduction to stock market data analysis with r (part 1)   NaN\n",
       "42749       647.0                                     getting started with apache mahout   NaN\n",
       "42750       965.0                     data visualization playbook: revisiting the basics   NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The articles with no email/user interaction in the df dataframe\n",
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of unique articles that have no user interaction in the df dataframe\n",
    "df[df.isna().any(axis=1)]['article_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique articles that have at least one interaction is 714.\n",
      "The number of unique articles on the IBM platform is 1051.\n",
      "The number of unique users is 5148.\n",
      "The number of user-article interactions is 45993\n"
     ]
    }
   ],
   "source": [
    "unique_articles = df.article_id.nunique()\n",
    "print('The number of unique articles that have at least one interaction is {}.'.format(unique_articles))\n",
    "total_articles = df_content.article_id.nunique()\n",
    "print('The number of unique articles on the IBM platform is {}.'.format(total_articles))\n",
    "unique_users = df.email.nunique()\n",
    "print('The number of unique users is {}.'.format(unique_users))\n",
    "user_article_interactions = df[['email', 'article_id']].shape[0]\n",
    "print('The number of user-article interactions is {}'.format(user_article_interactions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` _In the cells below we find the most viewed `article_id`, as well as how often it was viewed. After talking to the company leaders, the `email_mapper` function was deemed a reasonable way to map users to ids. There were a small number of null values, and it was found that all of these null values likely belonged to a single user (which is how they are stored using the function below)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id\n",
       "1429.0    937\n",
       "1330.0    927\n",
       "1431.0    671\n",
       "1427.0    643\n",
       "1364.0    627\n",
       "Name: email, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many times each article is viewed\n",
    "df.groupby('article_id').count()['email'].sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id                                       528.0\n",
       "title                10 tips on using jupyter notebook\n",
       "email         7888dc37498447d0477be7ee2c4176543f5a6190\n",
       "Name: 1429, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The most viewed article\n",
    "df.loc[1429]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc_body           Homepage About membership Sign in Get started Homepage Roman Kierzkowski Blocked Unblo...\n",
       "doc_description    Jupyter Notebook (a.k.a iPython Notebook) is brilliant coding tool. It is ideal for do...\n",
       "doc_full_name                                                              10 tips on using Jupyter Notebook\n",
       "doc_status                                                                                              Live\n",
       "article_id                                                                                               528\n",
       "Name: 529, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The full information on the article NOTE: the 1 unit shift in article id between dataframes!!\n",
    "df_content.loc[529]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most viewed article_id in the dataset is 1429.0.\n",
      "The most viewed article in the dataset was viewed 937 times.\n"
     ]
    }
   ],
   "source": [
    "most_viewed_article_id = str(df.groupby('article_id').count()['email'].sort_values(ascending=False).index[0])\n",
    "print('The most viewed article_id in the dataset is {}.'.format(most_viewed_article_id))\n",
    "max_views = df.groupby('article_id').count()['email'].sort_values(ascending=False).iloc[0]\n",
    "print('The most viewed article in the dataset was viewed {} times.'.format(max_views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier data analysis and experimentation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                                                             title  user_id\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier data analysis and experimentation        1\n",
       "1      1314.0                                      healthcare python streaming application demo        2\n",
       "2      1429.0                                        use deep learning for image classification        3\n",
       "3      1338.0                                         ml optimization using cognitive assistant        4\n",
       "4      1276.0                                         deploy your python model as a restful api        5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map the user email to a user_id column and remove the email column\n",
    "\n",
    "def email_mapper():\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "# show header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you have everything right here! Nice job!\n"
     ]
    }
   ],
   "source": [
    "# Testing unit for the above defined variables\n",
    "\n",
    "sol_1_dict = {\n",
    "    '`50% of individuals have _____ or fewer interactions.`': median_val,\n",
    "    '`The total number of user-article interactions in the dataset is ______.`': user_article_interactions,\n",
    "    '`The maximum number of user-article interactions by any 1 user is ______.`': max_views_by_user,\n",
    "    '`The most viewed article in the dataset was viewed _____ times.`': max_views,\n",
    "    '`The article_id of the most viewed article is ______.`': most_viewed_article_id,\n",
    "    '`The number of unique articles that have at least 1 rating ______.`': unique_articles,\n",
    "    '`The number of unique users in the dataset is ______`': unique_users,\n",
    "    '`The number of unique articles on the IBM platform`': total_articles\n",
    "}\n",
    "\n",
    "# Test your dictionary against the solution\n",
    "t.sol_1_test(sol_1_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Rank\">Part II: Rank-Based Recommendations</a>\n",
    "\n",
    "This dataset does not contain ratings for whether a user liked an article or not.  We only know that a user has interacted with an article.  In these cases, the popularity of an article can really only be based on how often an article was interacted with.\n",
    "\n",
    "`1.` _The next function returns the **n** top articles ordered with most interactions at the top. The function is also tested below._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['use deep learning for image classification',\n",
       " 'insights from new york car accident reports']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the approach used in the function\n",
    "list(df.groupby('title').count()['user_id'].sort_values(ascending=False).index[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_articles(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top n article titles \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    top_articles = list(df.groupby('title').count()['user_id'].sort_values(ascending=False).index[:n])\n",
    "    # Return the top article titles from df \n",
    "    return top_articles \n",
    "\n",
    "def get_top_article_ids(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article tids\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    top_articles_ids = list(df.groupby('article_id').count()['user_id'].sort_values(ascending=False).index[:n])\n",
    "    # Return the top article ids\n",
    "    return top_articles_ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['use deep learning for image classification', 'insights from new york car accident reports', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model']\n",
      "[1429.0, 1330.0, 1431.0, 1427.0, 1364.0, 1314.0, 1293.0, 1170.0, 1162.0, 1304.0]\n"
     ]
    }
   ],
   "source": [
    "print(get_top_articles(10))\n",
    "print(get_top_article_ids(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your top_5 looks like the solution list! Nice job.\n",
      "Your top_10 looks like the solution list! Nice job.\n",
      "Your top_20 looks like the solution list! Nice job.\n"
     ]
    }
   ],
   "source": [
    "# Test the function by returning the top 5, 10, and 20 articles\n",
    "top_5 = get_top_articles(5)\n",
    "top_10 = get_top_articles(10)\n",
    "top_20 = get_top_articles(20)\n",
    "\n",
    "# Test each of the three lists from above\n",
    "t.sol_2_test(get_top_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"User-User\">Part III: User-User Based Collaborative Filtering</a>\n",
    "\n",
    "\n",
    "`1.` Reformat the `df` dataframe to be shaped with users as the rows and articles as the columns.  \n",
    "\n",
    "* Each `user` appears in each row once.\n",
    "\n",
    "* Each `article` shows up in only one `column`.  \n",
    "\n",
    "* **If a user has interacted with an article, a 1 is placed where the user-row meets for that article-column**.  It does not matter how many times a user has interacted with the article, all entries where a user has interacted with an article are **1**.  \n",
    "\n",
    "* **If a user has not interacted with an item, a zero is placed where the user-row meets for that article-column**. \n",
    "\n",
    "The tests are used to make sure the basic structure of the matrix matches what is expected by the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the user-article matrix with 1's and 0's\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df (pandas dataframe) - article_id, title, user_id are the columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item (nd array) - user item matrix \n",
    "    \n",
    "    Description:\n",
    "    Return a matrix with user ids as rows and article ids on the columns,\n",
    "    with 1 values where a user interacted with an article and a 0 otherwise.\n",
    "    '''\n",
    "    \n",
    "    # Create new column that keeps track of user_article interaction\n",
    "    df['interact'] = 1\n",
    "    # Transform df so that every user is on a row and every article corresponds to a column\n",
    "    user_item = df.groupby(['user_id', 'article_id'])['interact'].first().unstack()\n",
    "    # Fill in NaN with 0 in the user_item matrix\n",
    "    user_item.fillna(0, inplace = True)\n",
    "    \n",
    "    return user_item # return the user_item matrix \n",
    "\n",
    "user_item = create_user_item_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have passed our quick tests!  Please proceed!\n"
     ]
    }
   ],
   "source": [
    "# Tests: You should just need to run this cell.  Don't change the code.\n",
    "assert user_item.shape[0] == 5149, \"Oops!  The number of users in the user-article matrix doesn't look right.\"\n",
    "assert user_item.shape[1] == 714, \"Oops!  The number of articles in the user-article matrix doesn't look right.\"\n",
    "assert user_item.sum(axis=1)[1] == 36, \"Oops!  The number of articles seen by user 1 doesn't look right.\"\n",
    "print(\"You have passed our quick tests!  Please proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` _The function below takes a `user_id` and provide an ordered list of the most similar users to that user (from most similar to least similar). The returned result should not contain the provided `user_id`, as we know that each user is similar to him/herself. Because the results for each user here are binary, it (perhaps) makes sense to compute similarity as the dot product of two users. \n",
    "\n",
    "_We use the tests to test the function._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_users(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user_id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    similar_users - (list) an ordered list where the closest users (largest dot product users)\n",
    "                    are listed first\n",
    "    \n",
    "    Description:\n",
    "    Computes the similarity of every pair of users based on the dot product\n",
    "    Returns an ordered\n",
    "    \n",
    "    '''\n",
    "    # compute similarity of each user to the provided user\n",
    "    user_similarities = user_item.dot(user_item.loc[user_id])\n",
    "\n",
    "    # sort by similarity\n",
    "    sorted_similarities = user_similarities.sort_values(ascending=False)\n",
    "\n",
    "    # create list of just the ids\n",
    "    similars = list(sorted_similarities.index)\n",
    "   \n",
    "    # remove the own user's id\n",
    "    most_similar_users = similars[1:]\n",
    "       \n",
    "    return most_similar_users # return a list of the users in order from most to least similar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most similar users to user 1 are: [3933, 23, 3782, 203, 4459, 3870, 131, 4201, 46, 5041]\n",
      "The 5 most similar users to user 3933 are: [3933, 23, 3782, 203, 4459]\n",
      "The 3 most similar users to user 46 are: [4201, 3782, 23]\n"
     ]
    }
   ],
   "source": [
    "# Do a spot check of your function\n",
    "print(\"The 10 most similar users to user 1 are: {}\".format(find_similar_users(1)[:10]))\n",
    "print(\"The 5 most similar users to user 3933 are: {}\".format(find_similar_users(3933)[:5]))\n",
    "print(\"The 3 most similar users to user 46 are: {}\".format(find_similar_users(46)[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` _Now that we have a function that provides the most similar users to each user, we will want to use these users to find articles we can recommend.  The functions below return the articles we would recommend to each user._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_names(article_ids, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_ids - (list) a list of article ids\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the title column)\n",
    "    '''\n",
    "    article_names = [df[df['article_id'] == float(x)]['title'].unique()[0] for x in article_ids]\n",
    "    # Return the article names associated with list of article ids\n",
    "    return article_names \n",
    "\n",
    "\n",
    "def get_user_articles(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_ids - (list) a list of the article ids seen by the user\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the doc_full_name column in df_content)\n",
    "    \n",
    "    Description:\n",
    "    Provides a list of the article_ids and article titles that have been seen by a user\n",
    "    '''\n",
    "\n",
    "    article_ids = user_item.loc[user_id][user_item.loc[user_id] == 1].index.astype('str').to_list()\n",
    "    article_names = get_article_names(article_ids, df)\n",
    "    return article_ids, article_names # return the ids and names\n",
    "\n",
    "\n",
    "def user_user_recs(user_id, m):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    Users who are the same closeness are chosen arbitrarily as the 'next' user\n",
    "    \n",
    "    For the user where the number of recommended articles starts below m \n",
    "    and ends exceeding m, the last items are chosen arbitrarily\n",
    "    \n",
    "    '''\n",
    "    # articles_seen by user (we don't want to recommend these)\n",
    "    articles_seen = get_user_articles(user_id, user_item)[0]\n",
    "    # find the similar users\n",
    "    similar_users = find_similar_users(user_id)\n",
    "    \n",
    "    # list of recommended articles\n",
    "    recs = []\n",
    "    \n",
    "    for user in similar_users:\n",
    "        user_list = get_user_articles(user, user_item)[0]\n",
    "        recs_update = np.setdiff1d(user_list, articles_seen)\n",
    "        recs.extend(np.setdiff1d(recs_update, recs))\n",
    "     \n",
    "        if len(recs) >= m:\n",
    "            break\n",
    "    \n",
    "    return recs[:m] # return recommendations for this user_id    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recommender systems: approaches & algorithms',\n",
       " '1448    i ranked every intro to data science course on...\\nName: title, dtype: object',\n",
       " 'data tidying in data science experience',\n",
       " 'a tensorflow regression model to predict house values',\n",
       " '520    using notebooks with pixiedust for fast, flexi...\\nName: title, dtype: object',\n",
       " 'airbnb data for analytics: mallorca reviews',\n",
       " 'airbnb data for analytics: vancouver listings',\n",
       " 'analyze facebook data using ibm watson and watson studio',\n",
       " 'analyze accident reports on amazon emr spark',\n",
       " 'analyze energy consumption in buildings']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Results\n",
    "get_article_names(user_user_recs(1, 10)) # Return 10 recommendations for user 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, you passed all of our tests!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "# Test the functions here - No need to change this code - just run this cell\n",
    "assert set(get_article_names(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_article_names(['1320.0', '232.0', '844.0'])) == set(['housing (2015): united states demographic measures','self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_user_articles(20)[0]) == set(['1320.0', '232.0', '844.0'])\n",
    "assert set(get_user_articles(20)[1]) == set(['housing (2015): united states demographic measures', 'self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook'])\n",
    "assert set(get_user_articles(2)[0]) == set(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])\n",
    "assert set(get_user_articles(2)[1]) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis'])\n",
    "print(\"If this is all you see, you passed all of our tests!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` _Now we are going to improve the consistency of the **user_user_recs** function from above._\n",
    "\n",
    "* _Instead of arbitrarily choosing when we obtain users who are all the same closeness to a given user - choose the users that have the most total article interactions before choosing those with fewer article interactions._\n",
    "\n",
    "* _Instead of arbitrarily choosing articles from the user where the number of recommended articles starts below m and ends exceeding m, choose articles with the articles with the most total interactions before choosing those with fewer total interactions. This ranking should be what would be obtained from the **top_articles** function written earlier._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample user id\n",
    "user_id = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5148"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order the other users based on similarity\n",
    "neighbor_id = find_similar_users(user_id)\n",
    "len(neighbor_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record the similarity measure, i.e. the dot product with user_id \n",
    "similarity = [user_item.loc[neighbor].dot(user_item.loc[user_id]) for neighbor in neighbor_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of views for each user\n",
    "num_interactions = [df[df['user_id'] == x].shape[0] for x in neighbor_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary \n",
    "neighbors_df = {'neighbor_id': neighbor_id,\n",
    "               'similarity': similarity,\n",
    "               'num_interactions': num_interactions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from dictionary\n",
    "neighbors_df = pd.DataFrame(data=neighbors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbor_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>num_interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3691</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>12.0</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3782</td>\n",
       "      <td>12.0</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>11.0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3169</td>\n",
       "      <td>11.0</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighbor_id  similarity  num_interactions\n",
       "0         3691        28.0                33\n",
       "1           23        12.0               364\n",
       "2         3782        12.0               363\n",
       "3          170        11.0               116\n",
       "4         3169        11.0               114"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the output\n",
    "neighbors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbor_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>num_interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3691</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>12.0</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighbor_id  similarity  num_interactions\n",
       "0         3691        28.0                33\n",
       "1           23        12.0               364"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the values\n",
    "neighbors_df.sort_values(by=['similarity', 'num_interactions'], ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbor_id         72.0\n",
       "similarity           8.0\n",
       "num_interactions    49.0\n",
       "Name: 17, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the information of the user_id we started with\n",
    "neighbors_df.loc[user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3691, 23, 3782, 170, 3169, 49, 3764, 3697, 98, 256]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of the most simlar users\n",
    "neighbor_list = neighbor_id[:10]\n",
    "neighbor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get one member from the neighbors list\n",
    "user = neighbor_list[1]\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # get the articles seen by the similar user\n",
    "similar_seen = get_user_articles(user, user_item)[0]\n",
    "len(similar_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['108.0', '146.0', '158.0', '162.0']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the articles seen by user_id member\n",
    "articles_seen =  get_user_articles(user_id, user_item)[0]\n",
    "articles_seen[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the articles seen by user_id from neighbor's list\n",
    "# these are the articles to recommend\n",
    "articles_to_rec = np.setdiff1d(similar_seen, articles_seen)\n",
    "len(articles_to_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the final list of articles to recommend\n",
    "recs_ids = []\n",
    "# the articles seen by similar user to add to the recommended list\n",
    "# remove those articles already in the list\n",
    "articles_to_add = np.setdiff1d(articles_to_rec, recs_ids)\n",
    "len(articles_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000.0, 1014.0]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the next step we need article ids as float or integer\n",
    "articles_ids = [float(x) for x in articles_to_add]\n",
    "articles_ids[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1429.0, 1330.0]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the article ids\n",
    "df_reduced=df[df['article_id'].isin(articles_ids)]\n",
    "df_reduced.groupby('article_id').count()['title'].sort_values(ascending=False).index.to_list()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sorted_users(user_id, df=df, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int)\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "            1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "            \n",
    "    OUTPUT:\n",
    "    neighbors_df - (pandas dataframe) a dataframe with:\n",
    "                    neighbor_id - is a neighbor user_id\n",
    "                    similarity - measure of the similarity of each user to the provided user_id\n",
    "                    num_interactions - the number of articles viewed by the user - if a u\n",
    "                    \n",
    "    Other Details - sort the neighbors_df by the similarity and then by number of interactions where \n",
    "                    highest of each is higher in the dataframe\n",
    "     \n",
    "    '''\n",
    "    # order the other users based on similarity with member user_id\n",
    "    neighbor_id = find_similar_users(user_id)\n",
    "    # record the similarity measure, i.e. the dot product with user_id \n",
    "    similarity = [user_item.loc[neighbor].dot(user_item.loc[user_id]) for neighbor in neighbor_id]\n",
    "    # find the number of views/interactions for each user\n",
    "    num_interactions = [df[df['user_id'] == x].shape[0] for x in neighbor_id]\n",
    "    \n",
    "    # create a dataframe \n",
    "    neighbors_df = pd.DataFrame(data={'neighbor_id': neighbor_id,\n",
    "                                      'similarity': similarity,\n",
    "                                      'num_interactions': num_interactions})\n",
    "    # drop the row corresponding to the member user_id\n",
    "    neighbors_df.drop(user_id, axis = 0, inplace = True)\n",
    "    \n",
    "    # sort by similarity and num_interactions                 \n",
    "    neighbors_df.sort_values(by = ['similarity', 'num_interactions'], \n",
    "                             inplace=True, \n",
    "                             ascending=(False, False))   \n",
    "    \n",
    "    # Return the dataframe specified in the doc_string\n",
    "    return neighbors_df \n",
    "\n",
    "\n",
    "def user_user_recs_part2(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user by article id\n",
    "    rec_names - (list) a list of recommendations for the user by article title\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    * Choose the users that have the most total article interactions \n",
    "    before choosing those with fewer article interactions.\n",
    "\n",
    "    * Choose articles with the articles with the most total interactions \n",
    "    before choosing those with fewer total interactions. \n",
    "   \n",
    "    '''\n",
    "    # list of recommended articles by id, and by title\n",
    "    recs_ids = []\n",
    "    \n",
    "    # articles_seen by user (we don't want to recommend these)\n",
    "    articles_seen = get_user_articles(user_id, user_item)[0]\n",
    "    \n",
    "    # similar users with most article views\n",
    "    similar_users = get_top_sorted_users(user_id, df, user_item)\n",
    "    \n",
    "    for user in similar_users['neighbor_id'].values:\n",
    "        \n",
    "        # get the articles seen by the similar user\n",
    "        similar_seen = get_user_articles(user, user_item)[0]\n",
    "        \n",
    "        # remove the articles in articles_seen\n",
    "        articles_to_rec = np.setdiff1d(similar_seen, articles_seen)\n",
    "        \n",
    "        # remove the articles already added to the recs list\n",
    "        articles_to_add = np.setdiff1d(articles_to_rec, recs_ids)\n",
    "        \n",
    "        # rewrite the recommended article ids as float \n",
    "        articles_ids = [float(x) for x in articles_to_add]\n",
    "        \n",
    "        # sort the articles by popularity, i.e. number of views\n",
    "        df_red = df[df['article_id'].isin(articles_ids)]\n",
    "        sorted_articles=df_red.groupby('article_id').count()['title'].sort_values(ascending=False).index.to_list()\n",
    "       \n",
    "        # add the sorted article ids\n",
    "        recs_ids.extend(sorted_articles)\n",
    "        \n",
    "        # break when we have enough articles to recommend\n",
    "        if len(recs_ids) >= m:\n",
    "            break\n",
    "    \n",
    "    # retain the first m recommendations\n",
    "    recs = recs_ids[:m]\n",
    "    \n",
    "    # get the articles names\n",
    "    rec_names = get_article_names(recs, df)\n",
    "    \n",
    "    return recs, rec_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 recommendations for user 20 are the following article ids:\n",
      "[1330.0, 1427.0, 1364.0, 1170.0, 1162.0, 1304.0, 1351.0, 1160.0, 1354.0, 1368.0]\n",
      "\n",
      "The top 10 recommendations for user 20 are the following article names:\n",
      "['insights from new york car accident reports', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model', 'model bike sharing data with spss', 'analyze accident reports on amazon emr spark', 'movie recommender system with spark machine learning', 'putting a human face on machine learning']\n"
     ]
    }
   ],
   "source": [
    "# Quick spot check - don't change this code - just use it to test your functions\n",
    "rec_ids, rec_names = user_user_recs_part2(20, 10)\n",
    "print(\"The top 10 recommendations for user 20 are the following article ids:\")\n",
    "print(rec_ids)\n",
    "print()\n",
    "print(\"The top 10 recommendations for user 20 are the following article names:\")\n",
    "print(rec_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` _Based on the functions from above to we fill in the solutions to the dictionary below. Then test the dictionary against the solution. The code needed to answer each of the following comments below is provided._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests with a dictionary of results\n",
    "\n",
    "# Find the user that is most similar to user 1 \n",
    "user1_most_sim = get_top_sorted_users(1, df, user_item).loc[0]['neighbor_id']\n",
    "# Find the 10th most similar user to user 131\n",
    "user131_10th_sim = get_top_sorted_users(131, df, user_item).loc[10]['neighbor_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3933.0 242.0\n"
     ]
    }
   ],
   "source": [
    "print(user1_most_sim, user131_10th_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This all looks good!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "# Dictionary Test Here\n",
    "sol_5_dict = {\n",
    "    'The user that is most similar to user 1.': user1_most_sim, \n",
    "    'The user that is the 10th most similar to user 131': user131_10th_sim,\n",
    "}\n",
    "\n",
    "t.sol_5_test(sol_5_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6.` _If we were given a new user, which of the above functions would you be able to use to make recommendations?  Explain.  Can you think of a better way we might make recommendations?  Use the cell below to explain a better method for new users._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For a new use we recommend the most popular articles on the website, through `get_top_articles` and `get_top_article_ids` functions, as we don't have any information about user's preferences.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`7.` _Using the existing functions, we provide the top 10 recommended articles we would provide for a new user below. Test the function against the standard solution._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user = '0.0'\n",
    "\n",
    "# What would your recommendations be for this new user '0.0'?  As a new user, they have no observed articles.\n",
    "# Provide a list of the top 10 article ids you would give to \n",
    "new_user_recs = get_top_article_ids(10, df) # Your recommendations here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite recommendations as a set of strings\n",
    "new_user_recs = [str(x) for x in new_user_recs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "assert set(new_user_recs) == set(['1314.0','1429.0','1293.0','1427.0',\n",
    "                                  '1162.0','1364.0','1304.0','1170.0','1431.0','1330.0']), \"Oops! It makes sense that in this case we would want to recommend the most popular articles, because we don't know anything about these users.\"\n",
    "\n",
    "print(\"That's right!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Content-Recs\">Part IV: Content Based Recommendations</a>\n",
    "\n",
    "Another method we might use to make recommendations is to perform a ranking of the highest ranked articles associated with some term. We could consider content to be the `doc_body`, `doc_description`, or `doc_full_name`.  There isn't one way to create a content based recommendation, especially considering that each of these columns hold content related information.  \n",
    "\n",
    "`1.` _We will create a content based recommender based on `doc_description` and `full_doc_title` columns._  \n",
    "\n",
    "`2.` _We choose the most popular recommendations that meet the content criteria._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copies of the data\n",
    "df_copy = df.copy()\n",
    "df_content_copy = df_content.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['article_id', 'title', 'user_id', 'interact'], dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the data\n",
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id    float64\n",
       "title          object\n",
       "user_id         int64\n",
       "interact        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data types in df\n",
    "df_copy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id     int64\n",
       "title         object\n",
       "user_id        int64\n",
       "interact       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change datatype of article id in df\n",
    "df_copy['article_id'] = df_copy['article_id'].astype('int')\n",
    "\n",
    "# check the output\n",
    "df_copy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    healthcare python streaming application demo\n",
       "2      use deep learning for image classification\n",
       "3       ml optimization using cognitive assistant\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the titles in df\n",
    "df_copy.title[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase all titles in df dataframe\n",
    "df_copy['title'] = df_copy['title'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['doc_body', 'doc_description', 'doc_full_name', 'doc_status',\n",
       "       'article_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the content data\n",
    "df_content_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc_body           object\n",
       "doc_description    object\n",
       "doc_full_name      object\n",
       "doc_status         object\n",
       "article_id          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data types in df_content\n",
    "df_content_copy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VID...</td>\n",
       "      <td>Detect bad readings in real time using Python and Streaming Analytics.</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streaming Analytics</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n * kaggle.com\\r\\n\\r\\nCommunicating data s...</td>\n",
       "      <td>See the forest, see the trees. Here lies the challenge in both performing and presenti...</td>\n",
       "      <td>Communicating data science: A guide to presenting your work</td>\n",
       "      <td>Live</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    doc_body                                                                            doc_description                                                doc_full_name doc_status  article_id\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VID...                     Detect bad readings in real time using Python and Streaming Analytics.   Detect Malfunctioning IoT Sensors with Streaming Analytics       Live           0\n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n * kaggle.com\\r\\n\\r\\nCommunicating data s...  See the forest, see the trees. Here lies the challenge in both performing and presenti...  Communicating data science: A guide to presenting your work       Live           1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a closer look at the data\n",
    "df_content_copy.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the column doc_full_name to title\n",
    "df_content_copy.rename(columns={'doc_full_name': 'title'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>title</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VID...</td>\n",
       "      <td>Detect bad readings in real time using Python and Streaming Analytics.</td>\n",
       "      <td>detect malfunctioning iot sensors with streaming analytics</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n * kaggle.com\\r\\n\\r\\nCommunicating data s...</td>\n",
       "      <td>See the forest, see the trees. Here lies the challenge in both performing and presenti...</td>\n",
       "      <td>communicating data science: a guide to presenting your work</td>\n",
       "      <td>Live</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Paths\\r\\n * Courses * Our Courses\\r\\n    * ...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Big Data.</td>\n",
       "      <td>this week in data science (april 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCALE - BOOST THE PERFORMANCE OF YOUR\\r\\nDI...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of scaling persistent storage, but introdu...</td>\n",
       "      <td>datalayer conference: boost the performance of your distributed database</td>\n",
       "      <td>Live</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VID...</td>\n",
       "      <td>This video demonstrates the power of IBM DataScience Experience using a simple New Yor...</td>\n",
       "      <td>analyze ny restaurant data using spark in dsx</td>\n",
       "      <td>Live</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    doc_body                                                                            doc_description                                                                     title doc_status  article_id\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VID...                     Detect bad readings in real time using Python and Streaming Analytics.                detect malfunctioning iot sensors with streaming analytics       Live           0\n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n * kaggle.com\\r\\n\\r\\nCommunicating data s...  See the forest, see the trees. Here lies the challenge in both performing and presenti...               communicating data science: a guide to presenting your work       Live           1\n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Paths\\r\\n * Courses * Our Courses\\r\\n    * ...                                      Here’s this week’s news in Data Science and Big Data.                                this week in data science (april 18, 2017)       Live           2\n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCALE - BOOST THE PERFORMANCE OF YOUR\\r\\nDI...  Learn how distributed DBs solve the problem of scaling persistent storage, but introdu...  datalayer conference: boost the performance of your distributed database       Live           3\n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VID...  This video demonstrates the power of IBM DataScience Experience using a simple New Yor...                             analyze ny restaurant data using spark in dsx       Live           4"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lower case all the article titles\n",
    "df_content_copy['title'] = df_content_copy['title'].apply(lambda x: x.lower())\n",
    "\n",
    "# check the outcome\n",
    "df_content_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>detect malfunctioning iot sensors with streaming analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>communicating data science: a guide to presenting your work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>this week in data science (april 18, 2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>datalayer conference: boost the performance of your distributed database</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>analyze ny restaurant data using spark in dsx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                                                     title\n",
       "0           0                detect malfunctioning iot sensors with streaming analytics\n",
       "1           1               communicating data science: a guide to presenting your work\n",
       "2           2                                this week in data science (april 18, 2017)\n",
       "3           3  datalayer conference: boost the performance of your distributed database\n",
       "4           4                             analyze ny restaurant data using spark in dsx"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# form a dataframe that has  columns: title, doc_description and article_id \n",
    "df_cont = df_content_copy[['article_id', 'title']]\n",
    "\n",
    "# check the output\n",
    "df_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier data analysis and experimentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                                                             title\n",
       "0        1430  using pixiedust for fast, flexible, and easier data analysis and experimentation\n",
       "1        1314                                      healthcare python streaming application demo\n",
       "2        1429                                        use deep learning for image classification\n",
       "3        1338                                         ml optimization using cognitive assistant\n",
       "4        1276                                         deploy your python model as a restful api"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe for article titles in df\n",
    "df_titles = df_copy[['article_id', 'title']]\n",
    "\n",
    "df_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id    0\n",
       "title         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df_titles.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the duplicates from dataframe df_titles\n",
    "df_titles = df_titles[~df_titles.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1341, 2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the two dataframes so all available articles are included\n",
    "df_full = pd.merge(df_cont, df_titles,\n",
    "                  left_on = ['article_id', 'title'],\n",
    "                  right_on = ['article_id', 'title'],\n",
    "                  how = 'outer')\n",
    "\n",
    "# check the outcome\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>detect malfunctioning iot sensors with streaming analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>communicating data science: a guide to presenting your work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>this week in data science (april 18, 2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>datalayer conference: boost the performance of your distributed database</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>analyze ny restaurant data using spark in dsx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                                                     title\n",
       "0           0                detect malfunctioning iot sensors with streaming analytics\n",
       "1           1               communicating data science: a guide to presenting your work\n",
       "2           2                                this week in data science (april 18, 2017)\n",
       "3           3  datalayer conference: boost the performance of your distributed database\n",
       "4           4                             analyze ny restaurant data using spark in dsx"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview the output\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id    0\n",
       "title         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df_full.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process the Text and Create TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Contains the pre-processing steps for a document:\n",
    "        - tokenize\n",
    "        - lemmatize\n",
    "        - lowercasing\n",
    "        - removes stopwords in English language\n",
    "        \n",
    "    INPUT (string) - raw message\n",
    "    OUTPUT (list)  - clean tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove punctuation and unusual characters \n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text).strip()\n",
    "    \n",
    "    # split into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # lemmatize - reduce words to their root form\n",
    "    words = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
    "    \n",
    "    # case normalize and remove leading & trailing empty spaces\n",
    "    words = [w.lower().strip() for w in words]\n",
    "    \n",
    "    # remove stopwords, keep not and can\n",
    "    clean_words = [w for w in words if w not in stopwords.words('english') \n",
    "                   or w in ['not', 'can']]\n",
    "    \n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize)\n",
    "\n",
    "# construct the TF-IDF matrix \n",
    "tfidf_matrix = tfidf.fit_transform(df_full['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1341, 1970)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output the shape of the tfidf matrix\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the cosine similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1341, 1341)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the cosine similarity matrix \n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "# check the output\n",
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the recommender function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_info(article_id, df_full):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_id - (integer)\n",
    "    df_full - (pandas dataframe) contains article_id, title\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_title - (string) the article name associated with the provided article id\n",
    "    '''\n",
    "    \n",
    "    article_title = df_full[df_full['article_id']==article_id]['title'].unique()[0]\n",
    "    return article_id, article_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The title of the article with id = 542 is: getting started with python.\n"
     ]
    }
   ],
   "source": [
    "# print a sample output\n",
    "\n",
    "print('The title of the article with id = 542 is: {}.'.format(get_article_info(542, df_full)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in the article id as input and gives n recommendations\n",
    "def content_recommender(article_id, n, cosine_sim, df_full):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_id - (integer)\n",
    "    n - (integer) how many recommendations should be returned\n",
    "    cosine_sim  - (np.ndarray) matrix of cosine similarities\n",
    "    df - (pandas dataframe) contains title and article id\n",
    "    \n",
    "    OUTPUT:\n",
    "    recommended_articles  - (list) article ids and titles that are recommended, \n",
    "                             sorted by cosine similarity\n",
    "    '''\n",
    "    # get the information for the given article id\n",
    "    given_art = get_article_info(article_id, df_full)\n",
    "    \n",
    "    # obtain the matrix index that matches the article id\n",
    "    mat_index = df_full[df_full['article_id']==article_id].index.values[0]\n",
    "    \n",
    "    # sort the scores based on the cosine similarity scores with given article index, ignore the first entry\n",
    "    sim_scores = pd.Series(cosine_sim[mat_index]).sort_values(ascending=False).iloc[1:]\n",
    "    \n",
    "    # get the indices corresponding to the scores of the n most similar articles\n",
    "    sim_scores_n = list(sim_scores[:n+1].index.values)\n",
    "    \n",
    "    # return the top n most similar article_ids as a pandas dataframe\n",
    "    recommended_articles = df_full.iloc[sim_scores_n]\n",
    "    \n",
    "    return given_art, recommended_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 'working interactively with rstudio and notebooks in dsx'),\n",
       "      article_id                                                       title\n",
       " 373         373                               working with notebooks in dsx\n",
       " 763         763                  load data into rstudio for analysis in dsx\n",
       " 182         182                              overview of rstudio ide in dsx\n",
       " 355         355                    run shiny applications in rstudio in dsx\n",
       " 626         626       analyze db2 warehouse on cloud data in rstudio in dsx\n",
       " 665         665                       get social with your notebooks in dsx\n",
       " 958         958                  using dsx notebooks to analyze github data\n",
       " 474         474                          publish notebooks to github in dsx\n",
       " 930         930  how to use version control (github) in rstudio within dsx?\n",
       " 821         821                using rstudio in ibm data science experience\n",
       " 395         395                             run dsx notebooks on amazon emr)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give recommendations for the article with id 20\n",
    "article_id = 20\n",
    "rec_id20 = content_recommender(article_id, 10, cosine_sim, df_full)\n",
    "rec_id20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[373, 763, 182, 355, 626, 665, 958, 474, 930, 821, 395]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the article ids for the recommended articles for article_id=20\n",
    "rec_id20[1]['article_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((224, 'using apply, sapply, lapply in r'),\n",
       "       article_id                                                  title\n",
       " 103          103                    how to scale your analytics using r\n",
       " 986          986                                     r for data science\n",
       " 694          694       predict temperatures using dashdb, python, and r\n",
       " 919          919  watson speech-to-text services — tl;dr need not apply\n",
       " 933          933                                          workflow in r\n",
       " 1204        1056                               access postgresql with r)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make recommendations for article id 224 based on title\n",
    "content_recommender(224, 5, cosine_sim, df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Content Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_content_recs(user_id, cosine_sim, m=10, df=df, df_full=df_full):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    df - (pandas dataframe) contains user and articles interactions\n",
    "    df_full - (pandas dataframe) contains title and article id\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs_ids - (list) a list of recommendations for the user by article id\n",
    "    rec_names - (list) a list of recommendations for the user by article title\n",
    "    \n",
    "    Description:\n",
    "    Loops through the articles based on closeness to the articles seen by the user.\n",
    "    For each article seen by the user - finds n most similar articles based on content recommendations.\n",
    "    Does this until m recommendations are found.\n",
    "    \n",
    "    Notes:\n",
    "    * Choose the articles that have the most total article interactions \n",
    "    before choosing those with fewer article interactions.\n",
    "   \n",
    "    '''\n",
    "    # list of recommended articles by id, and by title\n",
    "    recommendations = []\n",
    "    \n",
    "    # articles_seen by user \n",
    "    articles_seen = get_user_articles(user_id, user_item)[0]\n",
    "    \n",
    "    # rewrite the recommended article ids as int\n",
    "    articles_ids_seen = [int(x[:-2]) for x in articles_seen]\n",
    "    \n",
    "    for art_id in articles_ids_seen:\n",
    "        \n",
    "        # get the n most similar articles \n",
    "        n = 10\n",
    "        similar_articles = content_recommender(art_id, n, cosine_sim, df_full)[1]['article_id'].tolist()\n",
    "\n",
    "        # remove the articles in articles_seen and available\n",
    "        articles_to_rec = np.setdiff1d(similar_articles, articles_ids_seen)\n",
    "        \n",
    "        # remove the articles already added to the recs list\n",
    "        articles_to_add = np.setdiff1d(articles_to_rec, recommendations)\n",
    "        \n",
    "        # add the sorted article ids\n",
    "        recommendations.extend(articles_to_add)\n",
    "        \n",
    "        # break when we have enough articles to recommend\n",
    "        if len(recs_ids) >= m:\n",
    "            break\n",
    "    \n",
    "    # retain the first m recommendations\n",
    "    recs = recommendations[:m]\n",
    "    \n",
    "    # get the articles titles\n",
    "    complete_recs = [get_article_info(int(idx), df_full) for idx in recs]\n",
    "    \n",
    "    return complete_recs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(43.0, 'deep learning with tensorflow course by big data university'),\n",
       " (109.0, 'tensorflow quick tips'),\n",
       " (111.0, 'tidy up your jupyter notebooks with scripts'),\n",
       " (112.0, 'building custom machine learning algorithms with apache systemml'),\n",
       " (164.0, 'learn tensorflow and deep learning together and now!'),\n",
       " (213.0, 'modeling energy usage in new york city'),\n",
       " (225.0,\n",
       "  'a visual explanation of the back propagation algorithm for neural networks'),\n",
       " (232.0, 'self-service data preparation with ibm data refinery'),\n",
       " (313.0, 'what is machine learning?'),\n",
       " (337.0, 'generalization in deep learning'),\n",
       " (379.0, 'data structures related to machine learning algorithms'),\n",
       " (482.0, 'using deep learning with keras to predict customer churn'),\n",
       " (528.0, '10 tips on using jupyter notebook'),\n",
       " (667.0, 'imitation learning in tensorflow (hopper from openai gym)'),\n",
       " (684.0, 'flexdashboard: interactive dashboards for r'),\n",
       " (723.0, '10 essential algorithms for machine learning engineers'),\n",
       " (903.0, 'an attempt to understand boosting algorithm(s)'),\n",
       " (939.0, 'deep learning from scratch i: computational graphs'),\n",
       " (967.0, 'ml algorithm != learning machine'),\n",
       " (1006.0,\n",
       "  'essentials of machine learning algorithms (with python and r codes)'),\n",
       " (1035.0, 'machine learning for the enterprise.'),\n",
       " (1154.0, 'airbnb data for analytics: vienna listings'),\n",
       " (1160.0, 'analyze accident reports on amazon emr spark'),\n",
       " (1162.0, 'analyze energy consumption in buildings'),\n",
       " (1165.0, 'analyze precipitation data'),\n",
       " (1172.0, 'apache spark lab, part 3: machine learning'),\n",
       " (1181.0, 'car performance data'),\n",
       " (1184.0, 'city population by sex, city and city type'),\n",
       " (1185.0, 'classify tumors with machine learning'),\n",
       " (1276.0, 'deploy your python model as a restful api'),\n",
       " (1277.0,\n",
       "  '54174    detect potentially malfunctioning sensors in r...\\nname: title, dtype: object'),\n",
       " (1304.0, 'gosales transactions for logistic regression model'),\n",
       " (1314.0, 'healthcare python streaming application demo'),\n",
       " (1320.0, 'housing (2015): united states demographic measures'),\n",
       " (1330.0, 'insights from new york car accident reports'),\n",
       " (1338.0, 'ml optimization using cognitive assistant'),\n",
       " (1351.0, 'model bike sharing data with spss'),\n",
       " (1357.0, 'overlapping co-cluster recommendation algorithm (ocular)'),\n",
       " (1360.0, 'pixieapp for outlier detection'),\n",
       " (1364.0, 'predicting churn with the spss random tree algorithm'),\n",
       " (1366.0,\n",
       "  'process events from the watson iot platform in a streams python application'),\n",
       " (1368.0, 'putting a human face on machine learning'),\n",
       " (1386.0, 'small steps to tensorflow'),\n",
       " (1396.0, 'times world university ranking analysis'),\n",
       " (1397.0, 'total employment, by economic activity (thousands)'),\n",
       " (1400.0, 'uci ml repository: chronic kidney disease data set'),\n",
       " (1427.0, 'use xgboost, scikit-learn & ibm watson machine learning apis'),\n",
       " (1429.0, 'use deep learning for image classification'),\n",
       " (1430.0,\n",
       "  'using pixiedust for fast, flexible, and easier data analysis and experimentation'),\n",
       " (1431.0, 'visualize car data with brunel'),\n",
       " (1433.0, 'visualize the 1854 london cholera outbreak'),\n",
       " (1437.0, 'what caused the challenger disaster?')]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# articles seen by user 40\n",
    "articles_seen = get_user_articles(40, user_item)[0]\n",
    "articles_ids_seen = [float(x) for x in articles_seen]\n",
    "articles_info = [get_article_info(index, df_full) for index in articles_ids_seen]\n",
    "articles_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(237, 'deep learning with data science experience'),\n",
       " (278, 'deep learning trends and an example'),\n",
       " (295, 'awesome deep learning papers'),\n",
       " (336, 'challenges in deep learning'),\n",
       " (500, 'the difference between ai, machine learning, and deep learning?'),\n",
       " (604, 'the 3 cs of big data'),\n",
       " (947, 'big data is better data'),\n",
       " (1004, 'how to get a job in deep learning'),\n",
       " (207, 'compose tips: dates and dating in mongodb'),\n",
       " (263, \"december '16 rstudio tips and tricks\")]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommendations for user 40 based on title content\n",
    "make_content_recs(40, cosine_sim, 10, df, df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[310, 362, 460, 878]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# articles seen by user 178\n",
    "articles_seen = get_user_articles(178, user_item)[0]\n",
    "articles_ids_seen = [int(x[:-2]) for x in articles_seen]\n",
    "articles_info = [get_article_info(index, df_full)[0] for index in articles_ids_seen]\n",
    "articles_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(142, 'neural networks for beginners: popular types and applications'),\n",
       " (225,\n",
       "  'a visual explanation of the back propagation algorithm for neural networks'),\n",
       " (303, 'backpropagation — how neural networks learn complex behaviors'),\n",
       " (464, 'use ibm data science experience to detect time series anomalies'),\n",
       " (465, 'introduction to neural networks, advantages and applications'),\n",
       " (641, 'perform sentiment analysis with lstms, using tensorflow'),\n",
       " (662, 'build deep learning architectures with neural network modeler'),\n",
       " (785, 'interactive time series with dygraphs'),\n",
       " (862, 'time series analysis using max/min and neuroscience'),\n",
       " (887,\n",
       "  'forgetting the past to learn the future: long short-term memory neural networks for time series prediction')]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommendations for user 178 based on title content\n",
    "make_content_recs(178, cosine_sim, 10, df, df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` _Now that you have put together your content-based recommendation system, use the cell below to write a summary explaining how your content based recommender works.  Do you see any possible improvements that could be made to your function?  Is there anything novel about your content based recommender?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The content based recommendations are based on the article title or on the article description. The corpus consists of one group of these documents. The text is processed by removing punctuation and stop words, it is lemmatized and split into tokens. Once processed the corpus is fed into a TdIdf Vectorizer that creates a matrix of scores. The cosine similarities between any two documents (rows in the similarity matrix) are computed and the results are saved in a 1051x1051 matrix.**\n",
    "\n",
    "**Given a user id, and assuming that the user has seen at least one article, the engine will recommend n content similar articles for each article seen by the user. Once this collection is created, it is sorted using the article popularity and m most popular articles are recommended.**\n",
    "\n",
    "**One way to improve these results is to use more efficient NLP techniques, such as word embedding. Another option would be to create meta data for the articles based on their descriptions and full text, both available in the `df_content` dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` _Use your content-recommendation system to make recommendations for the below scenarios based on the comments.  Again no tests are provided here, because there isn't one right answer that could be used to find these content based recommendations._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1429.0, 'use deep learning for image classification'),\n",
       " (1330.0, 'insights from new york car accident reports'),\n",
       " (1431.0, 'visualize car data with brunel'),\n",
       " (1427.0, 'use xgboost, scikit-learn & ibm watson machine learning apis'),\n",
       " (1364.0, 'predicting churn with the spss random tree algorithm'),\n",
       " (1314.0, 'healthcare python streaming application demo'),\n",
       " (1293.0,\n",
       "  'finding optimal locations of new store using decision optimization'),\n",
       " (1170.0, 'apache spark lab, part 1: basic concepts'),\n",
       " (1162.0, 'analyze energy consumption in buildings'),\n",
       " (1304.0, 'gosales transactions for logistic regression model')]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make recommendations for a brand new user - recommend the most popular articles\n",
    "new_user_recs = get_top_article_ids(10, df) \n",
    "new_user_recommendations = [get_article_info(art_id, df_full) for art_id in new_user_recs]\n",
    "new_user_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1427, 'use xgboost, scikit-learn & ibm watson machine learning apis'),\n",
       "       article_id                                                               title\n",
       " 124          124                      python machine learning: scikit-learn tutorial\n",
       " 809          809                                    use the machine learning library\n",
       " 313          313                                           what is machine learning?\n",
       " 1317        1175                breast cancer detection with xgboost, wml and scikit\n",
       " 893          893  use the machine learning library in ibm analytics for apache spark\n",
       " 161          161                           use the machine learning library in spark\n",
       " 437          437                            ibm watson machine learning: get started\n",
       " 122          122                              watson machine learning for developers\n",
       " 1320        1298                    from scikit-learn model to cloud with wml client\n",
       " 685          685                     working with data flows using  watson data apis\n",
       " 80            80                           leverage scikit-learn models with core ml)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make recommendations for a user who only has interacted with article id '1427.0'\n",
    "content_recommender(1427, 10, cosine_sim, df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Matrix-Fact\">Part V: Matrix Factorization</a>\n",
    "\n",
    "In this part of the notebook, you will build use matrix factorization to make article recommendations to the users on the IBM Watson Studio platform.\n",
    "\n",
    "`1.` You should have already created a **user_item** matrix above in **question 1** of **Part III** above.  This first question here will just require that you run the cells to get things set up for the rest of **Part V** of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matrix here\n",
    "user_item_matrix = pd.read_pickle('user_item_matrix.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick look at the matrix\n",
    "user_item_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` In this situation, you can use Singular Value Decomposition from [numpy](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.svd.html) on the user-item matrix.  Use the cell to perform SVD, and explain why this is different than in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SVD on the User-Item Matrix Here\n",
    "\n",
    "u, s, vt = # use the built in to get the three matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Provide your response here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Now for the tricky part, how do we choose the number of latent features to use?  Running the below cell, you can see that as the number of latent features increases, we obtain a lower error rate on making predictions for the 1 and 0 values in the user-item matrix.  Run the cell below to get an idea of how the accuracy improves as we increase the number of latent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_latent_feats = np.arange(10,700+10,20)\n",
    "sum_errs = []\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_new, u_new, vt_new = np.diag(s[:k]), u[:, :k], vt[:k, :]\n",
    "    \n",
    "    # take dot product\n",
    "    user_item_est = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(user_item_matrix, user_item_est)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs.append(err)\n",
    "    \n",
    "    \n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs)/df.shape[0]);\n",
    "plt.xlabel('Number of Latent Features');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.title('Accuracy vs. Number of Latent Features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` From the above, we can't really be sure how many features to use, because simply having a better way to predict the 1's and 0's of the matrix doesn't exactly give us an indication of if we are able to make good recommendations.  Instead, we might split our dataset into a training and test set of data, as shown in the cell below.  \n",
    "\n",
    "Use the code from question 3 to understand the impact on accuracy of the training and test sets of data with different numbers of latent features. Using the split below: \n",
    "\n",
    "* How many users can we make predictions for in the test set?  \n",
    "* How many users are we not able to make predictions for because of the cold start problem?\n",
    "* How many articles can we make predictions for in the test set?  \n",
    "* How many articles are we not able to make predictions for because of the cold start problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.head(40000)\n",
    "df_test = df.tail(5993)\n",
    "\n",
    "def create_test_and_train_user_item(df_train, df_test):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df_train - training dataframe\n",
    "    df_test - test dataframe\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item_train - a user-item matrix of the training dataframe \n",
    "                      (unique users for each row and unique articles for each column)\n",
    "    user_item_test - a user-item matrix of the testing dataframe \n",
    "                    (unique users for each row and unique articles for each column)\n",
    "    test_idx - all of the test user ids\n",
    "    test_arts - all of the test article ids\n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    \n",
    "    return user_item_train, user_item_test, test_idx, test_arts\n",
    "\n",
    "user_item_train, user_item_test, test_idx, test_arts = create_test_and_train_user_item(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the values in the dictionary below\n",
    "a = 662 \n",
    "b = 574 \n",
    "c = 20 \n",
    "d = 0 \n",
    "\n",
    "\n",
    "sol_4_dict = {\n",
    "    'How many users can we make predictions for in the test set?': # letter here, \n",
    "    'How many users in the test set are we not able to make predictions for because of the cold start problem?': # letter here, \n",
    "    'How many articles can we make predictions for in the test set?': # letter here,\n",
    "    'How many articles in the test set are we not able to make predictions for because of the cold start problem?': # letter here\n",
    "}\n",
    "\n",
    "t.sol_4_test(sol_4_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` Now use the **user_item_train** dataset from above to find U, S, and V transpose using SVD. Then find the subset of rows in the **user_item_test** dataset that you can predict using this matrix decomposition with different numbers of latent features to see how many features makes sense to keep based on the accuracy on the test data. This will require combining what was done in questions `2` - `4`.\n",
    "\n",
    "Use the cells below to explore how well SVD works towards making predictions for recommendations on the test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit SVD on the user_item_train matrix\n",
    "u_train, s_train, vt_train = # fit svd similar to above then use the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these cells to see how well you can use the training \n",
    "# decomposition to predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`6.` Use the cell below to comment on the results you found in the previous question. Given the circumstances of your results, discuss what you might do to determine if the recommendations you make with any of the above recommendation systems are an improvement to how users currently find articles? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='conclusions'></a>\n",
    "### Extras\n",
    "Using your workbook, you could now save your recommendations for each user, develop a class to make new predictions and update your results, and make a flask app to deploy your results.  These tasks are beyond what is required for this project.  However, from what you learned in the lessons, you certainly capable of taking these tasks on to improve upon your work here!\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "> Congratulations!  You have reached the end of the Recommendations with IBM project! \n",
    "\n",
    "> **Tip**: Once you are satisfied with your work here, check over your report to make sure that it is satisfies all the areas of the [rubric](https://review.udacity.com/#!/rubrics/2322/view). You should also probably remove all of the \"Tips\" like this one so that the presentation is as polished as possible.\n",
    "\n",
    "\n",
    "## Directions to Submit\n",
    "\n",
    "> Before you submit your project, you need to create a .html or .pdf version of this notebook in the workspace here. To do that, run the code cell below. If it worked correctly, you should get a return code of 0, and you should see the generated .html file in the workspace directory (click on the orange Jupyter icon in the upper left).\n",
    "\n",
    "> Alternatively, you can download this report as .html via the **File** > **Download as** submenu, and then manually upload it into the workspace directory by clicking on the orange Jupyter icon in the upper left, then using the Upload button.\n",
    "\n",
    "> Once you've done this, you can submit your project by clicking on the \"Submit Project\" button in the lower right here. This will create and submit a zip file with this .ipynb doc and the .html or .pdf version you created. Congratulations! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Recommendations_with_IBM.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
